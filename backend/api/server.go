package api

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"runtime"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/Codeyangyi/personal-ai-kb/config"
	"github.com/Codeyangyi/personal-ai-kb/embedding"
	"github.com/Codeyangyi/personal-ai-kb/llm"
	"github.com/Codeyangyi/personal-ai-kb/loader"
	"github.com/Codeyangyi/personal-ai-kb/rag"
	"github.com/Codeyangyi/personal-ai-kb/splitter"
	"github.com/Codeyangyi/personal-ai-kb/store"
	"github.com/google/uuid"
	"github.com/tmc/langchaingo/schema"

	_ "github.com/go-sql-driver/mysql"
)

// FileInfo æ–‡ä»¶ä¿¡æ¯
type FileInfo struct {
	ID         string    `json:"id"`
	Filename   string    `json:"filename"`
	Title      string    `json:"title"`   // æ–‡ä»¶æ ‡é¢˜ï¼ˆä»æ–‡ä»¶åæå–ï¼Œä¸å«æ‰©å±•åï¼‰
	Content    string    `json:"content"` // æ–‡ä»¶å†…å®¹é¢„è§ˆï¼ˆå‰1000å­—ç¬¦ï¼‰
	Size       int64     `json:"size"`
	UploadedAt time.Time `json:"uploadedAt"`
	Chunks     int       `json:"chunks"`
}

// DocGroup æ–‡æ¡£åˆ†ç»„ä¿¡æ¯ï¼ˆç”¨äºæŸ¥è¯¢ç»“æœå’Œå¼‚æ­¥æ£€æŸ¥ï¼‰
type DocGroup struct {
	DocTitle      string                   `json:"docTitle"`
	DocSource     string                   `json:"docSource"`
	SourceType    string                   `json:"sourceType"`              // "file" æˆ– "url"
	FileType      string                   `json:"fileType,omitempty"`      // æ–‡ä»¶ç±»å‹ï¼Œå¦‚ "pdf", "docx", "txt" ç­‰
	HasPublicForm bool                     `json:"hasPublicForm,omitempty"` // æ˜¯å¦åŒ…å«"å…¬å¼€å½¢å¼"å­—çœ¼
	FileID        string                   `json:"fileId,omitempty"`        // æ–‡ä»¶IDï¼Œç”¨äºä¸‹è½½
	Chunks        []map[string]interface{} `json:"chunks"`
}

// Server HTTP APIæœåŠ¡å™¨
type Server struct {
	ragSystem      *rag.RAG
	config         *config.Config
	embedder       *embedding.Embedder
	store          *store.QdrantStore
	llm            llm.LLM
	adminToken     string
	filesDir       string
	failedFilesDir string               // å¤±è´¥æ–‡ä»¶ç›®å½•
	files          map[string]*FileInfo // æ–‡ä»¶ID -> æ–‡ä»¶ä¿¡æ¯
	db             *sql.DB              // MySQL è¿æ¥ï¼ˆç”¨äºä¸šåŠ¡æ•°æ®ï¼Œå¦‚æ„è§åé¦ˆï¼‰
	
	// å¼‚æ­¥æ£€æŸ¥ç›¸å…³
	checkQueue     chan *DocGroup        // æ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—
	publicFormCache sync.Map             // ç¼“å­˜æ£€æŸ¥ç»“æœï¼šfileID -> bool
	checkWorkers   int                   // æ£€æŸ¥å·¥ä½œåç¨‹æ•°é‡
}

// NewServer åˆ›å»ºæ–°çš„APIæœåŠ¡å™¨
func NewServer(cfg *config.Config) (*Server, error) {
	// åˆ›å»ºåµŒå…¥å‘é‡ç”Ÿæˆå™¨
	embedder, err := embedding.NewEmbedder(
		cfg.EmbeddingProvider,
		cfg.OllamaBaseURL,
		cfg.EmbeddingModelName,
		cfg.SiliconFlowAPIKey,
	)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºåµŒå…¥å‘é‡ç”Ÿæˆå™¨å¤±è´¥: %v", err)
	}

	// åˆ›å»ºå‘é‡å­˜å‚¨
	vectorStore, err := store.NewQdrantStore(cfg.QdrantURL, cfg.QdrantAPIKey, cfg.CollectionName, embedder.GetEmbedder(), embedder)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºå‘é‡å­˜å‚¨å¤±è´¥: %v", err)
	}

	// åˆ›å»ºLLMå®¢æˆ·ç«¯ï¼ˆæ ¹æ®é…ç½®é€‰æ‹©Ollamaã€é€šä¹‰åƒé—®æˆ–Kimi2ï¼‰
	var llmClient llm.LLM
	if cfg.LLMProvider == "dashscope" {
		// ä½¿ç”¨é€šä¹‰åƒé—®
		llmClient, err = llm.NewDashScopeLLM(cfg.DashScopeAPIKey, cfg.DashScopeModel)
		if err != nil {
			return nil, fmt.Errorf("åˆ›å»ºé€šä¹‰åƒé—®å®¢æˆ·ç«¯å¤±è´¥: %v", err)
		}
		log.Printf("ä½¿ç”¨é€šä¹‰åƒé—®æ¨¡å‹: %s", cfg.DashScopeModel)
	} else if cfg.LLMProvider == "kimi" {
		// ä½¿ç”¨Kimi2
		llmClient, err = llm.NewKimiLLM(cfg.MoonshotAPIKey, cfg.MoonshotModel)
		if err != nil {
			return nil, fmt.Errorf("åˆ›å»ºKimi2å®¢æˆ·ç«¯å¤±è´¥: %v", err)
		}
		log.Printf("ä½¿ç”¨Kimi2æ¨¡å‹: %s", cfg.MoonshotModel)
	} else {
		// ä½¿ç”¨Ollama
		llmClient, err = llm.NewOllamaLLM(cfg.OllamaBaseURL, cfg.OllamaModel)
		if err != nil {
			return nil, fmt.Errorf("åˆ›å»ºOllamaå®¢æˆ·ç«¯å¤±è´¥: %v", err)
		}
		log.Printf("ä½¿ç”¨Ollamaæ¨¡å‹: %s", cfg.OllamaModel)
	}

	// åˆ›å»ºRAGç³»ç»Ÿ
	ragSystem := rag.NewRAG(embedder, vectorStore, llmClient, 3)

	// åˆå§‹åŒ– MySQLï¼ˆå¯é€‰ï¼‰
	var db *sql.DB
	if cfg.MySQLDSN != "" {
		var err error
		db, err = sql.Open("mysql", cfg.MySQLDSN)
		if err != nil {
			return nil, fmt.Errorf("è¿æ¥ MySQL å¤±è´¥: %v", err)
		}
		if err := db.Ping(); err != nil {
			return nil, fmt.Errorf("MySQL è¿æ¥æµ‹è¯•å¤±è´¥: %v", err)
		}

		// åˆ›å»ºæ„è§åé¦ˆè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
		createTableSQL := `CREATE TABLE IF NOT EXISTS feedbacks (
	id BIGINT AUTO_INCREMENT PRIMARY KEY,
	name VARCHAR(100) NOT NULL,
	title VARCHAR(255) NOT NULL,
	description TEXT NOT NULL,
	image VARCHAR(512) NULL,
	created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;`
		if _, err := db.Exec(createTableSQL); err != nil {
			return nil, fmt.Errorf("åˆ›å»ºåé¦ˆè¡¨å¤±è´¥: %v", err)
		}
		log.Println("MySQL å·²è¿æ¥ï¼Œåé¦ˆè¡¨åˆå§‹åŒ–æˆåŠŸ")
	} else {
		log.Println("æœªé…ç½® MYSQL_DSNï¼Œæ„è§åé¦ˆå°†ä¸ä¼šå†™å…¥æ•°æ®åº“")
	}

	// è·å–ç®¡ç†å‘˜tokenï¼ˆä»ç¯å¢ƒå˜é‡æˆ–é…ç½®ï¼‰
	adminToken := os.Getenv("ADMIN_TOKEN")
	if adminToken == "" {
		adminToken = "Zhzx@666" // é»˜è®¤tokenï¼Œç”Ÿäº§ç¯å¢ƒåº”è¯¥ä½¿ç”¨å¼ºå¯†ç 
		log.Println("è­¦å‘Š: ä½¿ç”¨é»˜è®¤ç®¡ç†å‘˜tokenï¼Œå»ºè®®è®¾ç½® ADMIN_TOKEN ç¯å¢ƒå˜é‡")
	}

	// åˆ›å»ºæ–‡ä»¶å­˜å‚¨ç›®å½•ï¼ˆåœ¨backendç›®å½•ä¸‹ï¼‰
	filesDir := "./uploads"
	if err := os.MkdirAll(filesDir, 0755); err != nil {
		return nil, fmt.Errorf("åˆ›å»ºæ–‡ä»¶å­˜å‚¨ç›®å½•å¤±è´¥: %v", err)
	}

	// åˆ›å»ºå¤±è´¥æ–‡ä»¶å­˜å‚¨ç›®å½•
	failedFilesDir := filepath.Join(filesDir, "failed")
	if err := os.MkdirAll(failedFilesDir, 0755); err != nil {
		return nil, fmt.Errorf("åˆ›å»ºå¤±è´¥æ–‡ä»¶å­˜å‚¨ç›®å½•å¤±è´¥: %v", err)
	}

	server := &Server{
		ragSystem:      ragSystem,
		config:         cfg,
		embedder:       embedder,
		store:          vectorStore,
		llm:            llmClient,
		adminToken:     adminToken,
		filesDir:       filesDir,
		failedFilesDir: failedFilesDir,
		files:          make(map[string]*FileInfo),
		db:             db,
		checkQueue:     make(chan *DocGroup, 100), // æ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—ï¼Œç¼“å†²åŒº100
		checkWorkers:   3,                         // 3ä¸ªå·¥ä½œåç¨‹å¤„ç†æ£€æŸ¥ä»»åŠ¡
	}

	// ä»ç£ç›˜æ¢å¤æ–‡ä»¶åˆ—è¡¨
	server.loadFilesFromDisk()

	// å¯åŠ¨å¼‚æ­¥æ£€æŸ¥å·¥ä½œåç¨‹
	server.startAsyncCheckWorkers()

	return server, nil
}

// Start å¯åŠ¨HTTPæœåŠ¡å™¨
func (s *Server) Start(port string) error {
	mux := http.NewServeMux()

	// Panicæ¢å¤ä¸­é—´ä»¶
	recoveryMiddleware := func(next http.Handler) http.Handler {
		return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
			defer func() {
				if err := recover(); err != nil {
					log.Printf("è¯·æ±‚å¤„ç†å‘ç”Ÿpanic: %v, è¯·æ±‚è·¯å¾„: %s, æ–¹æ³•: %s, å †æ ˆ: %s",
						err, r.URL.Path, r.Method, getStackTrace())
					w.Header().Set("Content-Type", "application/json")
					w.WriteHeader(http.StatusInternalServerError)
					json.NewEncoder(w).Encode(map[string]interface{}{
						"error":   "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
						"message": "è¯·æ±‚å¤„ç†æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•",
					})
				}
			}()
			next.ServeHTTP(w, r)
		})
	}

	// CORSä¸­é—´ä»¶
	corsMiddleware := func(next http.Handler) http.Handler {
		return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
			w.Header().Set("Access-Control-Allow-Origin", "*")
			w.Header().Set("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS")
			w.Header().Set("Access-Control-Allow-Headers", "Content-Type, Authorization")

			if r.Method == "OPTIONS" {
				w.WriteHeader(http.StatusOK)
				return
			}

			next.ServeHTTP(w, r)
		})
	}

	// APIè·¯ç”±
	mux.HandleFunc("/api/health", s.handleHealth)
	mux.HandleFunc("/api/upload", s.handleUpload)
	mux.HandleFunc("/api/upload-batch", s.handleBatchUpload)
	mux.HandleFunc("/api/query", s.handleQuery)
	mux.HandleFunc("/api/feedback", s.handleFeedback)
	mux.HandleFunc("/api/check-admin", s.handleCheckAdmin)
	mux.HandleFunc("/api/files/count", s.handleFileCount)
	mux.HandleFunc("/api/files", s.handleFileList)
	mux.HandleFunc("/api/files/", func(w http.ResponseWriter, r *http.Request) {
		if r.Method == "GET" {
			s.handleFileDownload(w, r)
		} else if r.Method == "DELETE" {
			s.handleFileDelete(w, r)
		} else {
			http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		}
	})

	// é™æ€æ–‡ä»¶æœåŠ¡ï¼ˆVueå‰ç«¯ï¼Œç›¸å¯¹äºbackendç›®å½•ï¼Œéœ€è¦å›åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼‰
	staticDir := "./frontend/dist"
	if _, err := os.Stat(staticDir); err == nil {
		fs := http.FileServer(http.Dir(staticDir))
		mux.Handle("/", http.StripPrefix("/", fs))
	} else {
		// å¦‚æœå‰ç«¯ç›®å½•ä¸å­˜åœ¨ï¼Œæä¾›ä¸€ä¸ªç®€å•çš„æç¤º
		mux.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
			if r.URL.Path != "/" {
				http.NotFound(w, r)
				return
			}
			w.Header().Set("Content-Type", "text/html; charset=utf-8")
			fmt.Fprintf(w, `
			<!DOCTYPE html>
			<html>
			<head>
				<title>ä¸ªäººAIçŸ¥è¯†åº“</title>
				<meta charset="utf-8">
			</head>
			<body>
				<h1>ä¸ªäººAIçŸ¥è¯†åº“ API æœåŠ¡å™¨</h1>
				<p>APIæœåŠ¡å™¨æ­£åœ¨è¿è¡Œ</p>
				<p>å‰ç«¯æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿å‰ç«¯å·²æ„å»ºå¹¶æ”¾ç½®åœ¨ frontend/dist ç›®å½•ä¸­</p>
			</body>
			</html>
			`)
		})
	}

	// å…ˆåº”ç”¨panicæ¢å¤ï¼Œå†åº”ç”¨CORS
	handler := recoveryMiddleware(corsMiddleware(mux))

	// åˆ›å»ºHTTPæœåŠ¡å™¨å¹¶è®¾ç½®è¶…æ—¶æ—¶é—´
	// ä¼˜åŒ–ï¼šå¢åŠ è¶…æ—¶æ—¶é—´ä»¥æ”¯æŒå¤§æ–‡ä»¶ä¸Šä¼ å’Œé•¿æ—¶é—´å‘é‡åŒ–
	server := &http.Server{
		Addr:         ":" + port,
		Handler:      handler,
		ReadTimeout:  30 * time.Minute,  // è¯»å–è¶…æ—¶ï¼š30åˆ†é’Ÿï¼ˆç”¨äºå¤§æ–‡ä»¶ä¸Šä¼ ï¼‰
		WriteTimeout: 30 * time.Minute,  // å†™å…¥è¶…æ—¶ï¼š30åˆ†é’Ÿï¼ˆç”¨äºå‘é‡åŒ–å“åº”ï¼‰
		IdleTimeout:  120 * time.Second, // ç©ºé—²è¿æ¥è¶…æ—¶ï¼š2åˆ†é’Ÿ
	}

	log.Printf("æœåŠ¡å™¨å¯åŠ¨åœ¨ http://localhost%s (è¶…æ—¶è®¾ç½®: è¯»å–/å†™å…¥30åˆ†é’Ÿ)", server.Addr)
	return server.ListenAndServe()
}

// handleHealth å¥åº·æ£€æŸ¥
func (s *Server) handleHealth(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]string{
		"status": "ok",
		"time":   time.Now().Format(time.RFC3339),
	})
}

// handleCheckAdmin æ£€æŸ¥ç®¡ç†å‘˜æƒé™
func (s *Server) handleCheckAdmin(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var req struct {
		Token string `json:"token"`
	}

	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request", http.StatusBadRequest)
		return
	}

	w.Header().Set("Content-Type", "application/json")
	if req.Token == s.adminToken {
		json.NewEncoder(w).Encode(map[string]interface{}{
			"isAdmin": true,
		})
	} else {
		json.NewEncoder(w).Encode(map[string]interface{}{
			"isAdmin": false,
		})
	}
}

// handleUpload å¤„ç†å•ä¸ªæ–‡ä»¶ä¸Šä¼ 
func (s *Server) handleUpload(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	// æ£€æŸ¥ç®¡ç†å‘˜æƒé™
	if !s.checkAdminAuth(r) {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}

	// è§£æmultipart form
	// ä¼˜åŒ–ï¼šç»Ÿä¸€æ–‡ä»¶å¤§å°é™åˆ¶ä¸º500MBï¼Œä¸æ‰¹é‡ä¸Šä¼ ä¿æŒä¸€è‡´
	err := r.ParseMultipartForm(500 << 20) // 500MBï¼ˆä»32MBå¢åŠ åˆ°500MBï¼Œä¸æ‰¹é‡ä¸Šä¼ ä¿æŒä¸€è‡´ï¼‰
	if err != nil {
		http.Error(w, fmt.Sprintf("Failed to parse form: %v (æ–‡ä»¶å¯èƒ½è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ500MB)", err), http.StatusBadRequest)
		return
	}

	file, header, err := r.FormFile("file")
	if err != nil {
		http.Error(w, fmt.Sprintf("Failed to get file: %v", err), http.StatusBadRequest)
		return
	}
	defer file.Close()

	// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆé€šè¿‡æ–‡ä»¶åå’Œå¤§å°åˆ¤æ–­ï¼‰
	if s.isFileDuplicate(header.Filename, header.Size) {
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"success":  false,
			"message":  fmt.Sprintf("æ–‡ä»¶ %s å·²å­˜åœ¨ï¼Œè¯·å‹¿é‡å¤ä¸Šä¼ ", header.Filename),
			"filename": header.Filename,
		})
		return
	}

	// ç”Ÿæˆæ–‡ä»¶IDå’Œä¿å­˜è·¯å¾„ï¼ˆä¿ç•™åŸæ–‡ä»¶åï¼‰
	fileID := uuid.New().String()
	// æ¸…ç†æ–‡ä»¶åä¸­çš„å±é™©å­—ç¬¦
	cleanedFilename := strings.ReplaceAll(header.Filename, "/", "_")
	cleanedFilename = strings.ReplaceAll(cleanedFilename, "\\", "_")
	cleanedFilename = strings.ReplaceAll(cleanedFilename, "..", "_")
	// æ ¼å¼ï¼š{fileID}_{åŸæ–‡ä»¶å}
	savedPath := filepath.Join(s.filesDir, fileID+"_"+cleanedFilename)

	// ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
	savedFile, err := os.Create(savedPath)
	if err != nil {
		http.Error(w, fmt.Sprintf("Failed to create file: %v", err), http.StatusInternalServerError)
		return
	}
	defer savedFile.Close()

	fileSize, err := io.Copy(savedFile, file)
	if err != nil {
		os.Remove(savedPath)
		http.Error(w, fmt.Sprintf("Failed to save file: %v", err), http.StatusInternalServerError)
		return
	}

	// åŠ è½½æ–‡æ¡£
	fileLoader := loader.NewFileLoader()
	docs, err := fileLoader.Load(savedPath)
	if err != nil {
		// ä¼˜åŒ–ï¼šæä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯ï¼ˆä¸æ‰¹é‡ä¸Šä¼ ä¿æŒä¸€è‡´ï¼‰
		errMsg := err.Error()
		userFriendlyMsg := errMsg
		if strings.Contains(errMsg, "åŠ å¯†") || strings.Contains(errMsg, "password") {
			userFriendlyMsg = "PDFæ–‡ä»¶å·²åŠ å¯†æˆ–å—å¯†ç ä¿æŠ¤ï¼Œè¯·å…ˆç§»é™¤å¯†ç ä¿æŠ¤"
		} else if strings.Contains(errMsg, "æŸå") || strings.Contains(errMsg, "corrupt") || strings.Contains(errMsg, "æ ¼å¼å¼‚å¸¸") || strings.Contains(errMsg, "malformed") {
			userFriendlyMsg = "PDFæ–‡ä»¶å¯èƒ½å·²æŸåæˆ–æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·å°è¯•ç”¨PDFé˜…è¯»å™¨æ‰“å¼€å¹¶é‡æ–°ä¿å­˜"
		} else if strings.Contains(errMsg, "stream") || strings.Contains(errMsg, "ç»“æ„ä¸å®Œæ•´") {
			userFriendlyMsg = "PDFæ–‡ä»¶æ ¼å¼å¼‚å¸¸ï¼Œå¯èƒ½æ˜¯æ‰«æç‰ˆPDFï¼ˆå›¾ç‰‡æ ¼å¼ï¼‰æˆ–æ–‡ä»¶ç»“æ„ä¸å®Œæ•´ã€‚è¯·å°è¯•ç”¨PDFé˜…è¯»å™¨æ‰“å¼€å¹¶é‡æ–°ä¿å­˜ï¼Œæˆ–ä½¿ç”¨OCRå·¥å…·æå–æ–‡æœ¬"
		} else if strings.Contains(errMsg, "æ‰«æç‰ˆ") || strings.Contains(errMsg, "OCR") {
			userFriendlyMsg = "æ‰«æç‰ˆPDFï¼ˆçº¯å›¾ç‰‡ï¼‰ï¼Œæ— æ³•æå–æ–‡æœ¬ï¼Œè¯·ä½¿ç”¨OCRå·¥å…·æå–æ–‡æœ¬"
		} else if strings.Contains(errMsg, "empty") {
			userFriendlyMsg = "PDFæ–‡ä»¶ä¸ºç©º"
		} else if strings.Contains(errMsg, "too large") {
			userFriendlyMsg = "PDFæ–‡ä»¶è¿‡å¤§ï¼ˆæœ€å¤§500MBï¼‰"
		}

		// ä¿å­˜å¤±è´¥æ–‡ä»¶åˆ°å¤±è´¥ç›®å½•
		failureReason := fmt.Sprintf("åŠ è½½æ–‡æ¡£å¤±è´¥: %s", userFriendlyMsg)
		if saveErr := s.saveFailedFile(savedPath, header.Filename, failureReason); saveErr != nil {
			log.Printf("ä¿å­˜å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: %v", saveErr)
			os.Remove(savedPath) // å¦‚æœä¿å­˜å¤±è´¥ï¼Œåˆ é™¤åŸæ–‡ä»¶
		}

		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"success":  false,
			"message":  failureReason,
			"filename": header.Filename,
		})
		return
	}

	// æå–æ–‡ä»¶å†…å®¹é¢„è§ˆï¼ˆå‰1000å­—ç¬¦ï¼‰
	contentPreview := ""
	title := strings.TrimSuffix(header.Filename, filepath.Ext(header.Filename))
	if len(docs) > 0 {
		contentPreview = docs[0].PageContent
		if len(contentPreview) > 1000 {
			contentPreview = contentPreview[:1000] + "..."
		}
		// å°è¯•ä»æ–‡æ¡£å…ƒæ•°æ®è·å–æ ‡é¢˜
		if docTitle, ok := docs[0].Metadata["title"].(string); ok && docTitle != "" {
			title = docTitle
		}
	}

	// åˆ‡åˆ†æ–‡æ¡£
	textSplitter := splitter.NewTextSplitter(s.config.ChunkSize, s.config.ChunkOverlap)
	chunks, err := textSplitter.SplitDocuments(docs)
	if err != nil {
		// ä¿å­˜å¤±è´¥æ–‡ä»¶åˆ°å¤±è´¥ç›®å½•
		failureReason := fmt.Sprintf("åˆ‡åˆ†æ–‡æ¡£å¤±è´¥: %v", err)
		if saveErr := s.saveFailedFile(savedPath, header.Filename, failureReason); saveErr != nil {
			log.Printf("ä¿å­˜å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: %v", saveErr)
			os.Remove(savedPath) // å¦‚æœä¿å­˜å¤±è´¥ï¼Œåˆ é™¤åŸæ–‡ä»¶
		}
		http.Error(w, fmt.Sprintf("Failed to split document: %v", err), http.StatusInternalServerError)
		return
	}

	// æ·»åŠ åˆ°çŸ¥è¯†åº“
	ctx := context.Background()
	if err := s.ragSystem.AddDocuments(ctx, chunks); err != nil {
		// å‘é‡åŒ–å¤±è´¥ï¼šä¿å­˜å¤±è´¥æ–‡ä»¶åˆ°å¤±è´¥ç›®å½•
		failureReason := fmt.Sprintf("å‘é‡åŒ–å¤±è´¥: %v", err)
		if saveErr := s.saveFailedFile(savedPath, header.Filename, failureReason); saveErr != nil {
			log.Printf("ä¿å­˜å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: %v", saveErr)
			os.Remove(savedPath) // å¦‚æœä¿å­˜å¤±è´¥ï¼Œåˆ é™¤åŸæ–‡ä»¶
		}
		log.Printf("å‘é‡åŒ–å¤±è´¥ï¼Œå·²ä¿å­˜å¤±è´¥æ–‡ä»¶: %s, é”™è¯¯: %v", savedPath, err)
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"success":  false,
			"message":  fmt.Sprintf("æ–‡ä»¶å¤„ç†æˆåŠŸï¼Œä½†å‘é‡åŒ–å¤±è´¥: %vã€‚æ–‡ä»¶å·²ä¿å­˜åˆ°å¤±è´¥ç›®å½•ï¼Œè¯·ç¨åé‡è¯•ã€‚", err),
			"filename": header.Filename,
		})
		return
	}

	// ä¿å­˜æ–‡ä»¶ä¿¡æ¯
	fileInfo := &FileInfo{
		ID:         fileID,
		Filename:   header.Filename,
		Title:      title,
		Content:    contentPreview,
		Size:       fileSize,
		UploadedAt: time.Now(),
		Chunks:     len(chunks),
	}
	s.files[fileID] = fileInfo

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"success":  true,
		"message":  fmt.Sprintf("æˆåŠŸä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶: %sï¼Œå…± %d ä¸ªæ–‡æœ¬å—", header.Filename, len(chunks)),
		"chunks":   len(chunks),
		"fileId":   fileID,
		"filename": header.Filename,
	})
}

// handleBatchUpload å¤„ç†æ‰¹é‡æ–‡ä»¶ä¸Šä¼ 
func (s *Server) handleBatchUpload(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	// æ£€æŸ¥ç®¡ç†å‘˜æƒé™
	if !s.checkAdminAuth(r) {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}

	// è§£æmultipart form
	// ä¼˜åŒ–ï¼šå¢åŠ æ–‡ä»¶å¤§å°é™åˆ¶åˆ°500MBï¼Œæ”¯æŒæ›´å¤§çš„æ–‡ä»¶ä¸Šä¼ 
	err := r.ParseMultipartForm(500 << 20) // 500MBï¼ˆä»100MBå¢åŠ åˆ°500MBï¼‰
	if err != nil {
		http.Error(w, fmt.Sprintf("Failed to parse form: %v (æ–‡ä»¶å¯èƒ½è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ500MB)", err), http.StatusBadRequest)
		return
	}

	files := r.MultipartForm.File["files"]
	if len(files) == 0 {
		http.Error(w, "No files uploaded", http.StatusBadRequest)
		return
	}

	fileLoader := loader.NewFileLoader()
	textSplitter := splitter.NewTextSplitter(s.config.ChunkSize, s.config.ChunkOverlap)

	type FileResult struct {
		Filename string `json:"filename"`
		Success  bool   `json:"success"`
		Message  string `json:"message"`
		Chunks   int    `json:"chunks"`
		FileID   string `json:"fileId,omitempty"`
	}

	var results []FileResult
	var allChunks []schema.Document
	successCount := 0
	failCount := 0

	// å¤„ç†æ¯ä¸ªæ–‡ä»¶
	for _, fileHeader := range files {
		// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆé€šè¿‡æ–‡ä»¶åå’Œå¤§å°åˆ¤æ–­ï¼‰
		if s.isFileDuplicate(fileHeader.Filename, fileHeader.Size) {
			results = append(results, FileResult{
				Filename: fileHeader.Filename,
				Success:  false,
				Message:  "æ–‡ä»¶å·²å­˜åœ¨ï¼Œè¯·å‹¿é‡å¤ä¸Šä¼ ",
			})
			failCount++
			continue
		}

		file, err := fileHeader.Open()
		if err != nil {
			log.Printf("Failed to open file %s: %v", fileHeader.Filename, err)
			results = append(results, FileResult{
				Filename: fileHeader.Filename,
				Success:  false,
				Message:  fmt.Sprintf("æ‰“å¼€æ–‡ä»¶å¤±è´¥: %v", err),
			})
			failCount++
			continue
		}

		// ç”Ÿæˆæ–‡ä»¶IDå’Œä¿å­˜è·¯å¾„ï¼ˆä¿ç•™åŸæ–‡ä»¶åï¼‰
		fileID := uuid.New().String()
		// æ¸…ç†æ–‡ä»¶åä¸­çš„å±é™©å­—ç¬¦
		cleanedFilename := strings.ReplaceAll(fileHeader.Filename, "/", "_")
		cleanedFilename = strings.ReplaceAll(cleanedFilename, "\\", "_")
		cleanedFilename = strings.ReplaceAll(cleanedFilename, "..", "_")
		// æ ¼å¼ï¼š{fileID}_{åŸæ–‡ä»¶å}
		savedPath := filepath.Join(s.filesDir, fileID+"_"+cleanedFilename)

		// ä¿å­˜æ–‡ä»¶
		savedFile, err := os.Create(savedPath)
		if err != nil {
			file.Close()
			log.Printf("Failed to create file for %s: %v", fileHeader.Filename, err)
			results = append(results, FileResult{
				Filename: fileHeader.Filename,
				Success:  false,
				Message:  fmt.Sprintf("åˆ›å»ºæ–‡ä»¶å¤±è´¥: %v", err),
			})
			failCount++
			continue
		}

		fileSize, err := io.Copy(savedFile, file)
		file.Close()
		savedFile.Close()

		if err != nil {
			// ä¿å­˜å¤±è´¥æ–‡ä»¶åˆ°å¤±è´¥ç›®å½•
			failureReason := fmt.Sprintf("ä¿å­˜æ–‡ä»¶å¤±è´¥: %v", err)
			if saveErr := s.saveFailedFile(savedPath, fileHeader.Filename, failureReason); saveErr != nil {
				log.Printf("ä¿å­˜å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: %v", saveErr)
				os.Remove(savedPath) // å¦‚æœä¿å­˜å¤±è´¥ï¼Œåˆ é™¤åŸæ–‡ä»¶
			}
			log.Printf("Failed to save file %s: %v", fileHeader.Filename, err)
			results = append(results, FileResult{
				Filename: fileHeader.Filename,
				Success:  false,
				Message:  failureReason,
			})
			failCount++
			continue
		}

		// åŠ è½½æ–‡æ¡£
		docs, err := fileLoader.Load(savedPath)
		if err != nil {
			log.Printf("Failed to load document %s: %v", fileHeader.Filename, err)
			// æå–æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
			errMsg := err.Error()
			userFriendlyMsg := errMsg
			if strings.Contains(errMsg, "åŠ å¯†") || strings.Contains(errMsg, "password") {
				userFriendlyMsg = "PDFæ–‡ä»¶å·²åŠ å¯†æˆ–å—å¯†ç ä¿æŠ¤ï¼Œè¯·å…ˆç§»é™¤å¯†ç ä¿æŠ¤"
			} else if strings.Contains(errMsg, "æŸå") || strings.Contains(errMsg, "corrupt") || strings.Contains(errMsg, "æ ¼å¼å¼‚å¸¸") || strings.Contains(errMsg, "malformed") {
				userFriendlyMsg = "PDFæ–‡ä»¶å¯èƒ½å·²æŸåæˆ–æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·å°è¯•ç”¨PDFé˜…è¯»å™¨æ‰“å¼€å¹¶é‡æ–°ä¿å­˜"
			} else if strings.Contains(errMsg, "stream") || strings.Contains(errMsg, "ç»“æ„ä¸å®Œæ•´") {
				userFriendlyMsg = "PDFæ–‡ä»¶æ ¼å¼å¼‚å¸¸ï¼Œå¯èƒ½æ˜¯æ‰«æç‰ˆPDFï¼ˆå›¾ç‰‡æ ¼å¼ï¼‰æˆ–æ–‡ä»¶ç»“æ„ä¸å®Œæ•´ã€‚è¯·å°è¯•ç”¨PDFé˜…è¯»å™¨æ‰“å¼€å¹¶é‡æ–°ä¿å­˜ï¼Œæˆ–ä½¿ç”¨OCRå·¥å…·æå–æ–‡æœ¬"
			} else if strings.Contains(errMsg, "æ‰«æç‰ˆ") || strings.Contains(errMsg, "OCR") {
				userFriendlyMsg = "æ‰«æç‰ˆPDFï¼ˆçº¯å›¾ç‰‡ï¼‰ï¼Œæ— æ³•æå–æ–‡æœ¬ï¼Œè¯·ä½¿ç”¨OCRå·¥å…·æå–æ–‡æœ¬"
			} else if strings.Contains(errMsg, "empty") {
				userFriendlyMsg = "PDFæ–‡ä»¶ä¸ºç©º"
			} else if strings.Contains(errMsg, "too large") {
				userFriendlyMsg = "PDFæ–‡ä»¶è¿‡å¤§ï¼ˆæœ€å¤§100MBï¼‰"
			}

			// ä¿å­˜å¤±è´¥æ–‡ä»¶åˆ°å¤±è´¥ç›®å½•
			failureReason := fmt.Sprintf("åŠ è½½æ–‡æ¡£å¤±è´¥: %s", userFriendlyMsg)
			if saveErr := s.saveFailedFile(savedPath, fileHeader.Filename, failureReason); saveErr != nil {
				log.Printf("ä¿å­˜å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: %v", saveErr)
				os.Remove(savedPath) // å¦‚æœä¿å­˜å¤±è´¥ï¼Œåˆ é™¤åŸæ–‡ä»¶
			}

			results = append(results, FileResult{
				Filename: fileHeader.Filename,
				Success:  false,
				Message:  failureReason,
			})
			failCount++
			continue
		}

		// æå–æ–‡ä»¶å†…å®¹é¢„è§ˆï¼ˆå‰1000å­—ç¬¦ï¼‰
		contentPreview := ""
		title := strings.TrimSuffix(fileHeader.Filename, filepath.Ext(fileHeader.Filename))
		if len(docs) > 0 {
			contentPreview = docs[0].PageContent
			if len(contentPreview) > 1000 {
				contentPreview = contentPreview[:1000] + "..."
			}
			// å°è¯•ä»æ–‡æ¡£å…ƒæ•°æ®è·å–æ ‡é¢˜
			if docTitle, ok := docs[0].Metadata["title"].(string); ok && docTitle != "" {
				title = docTitle
			}
		}

		// åˆ‡åˆ†æ–‡æ¡£
		chunks, err := textSplitter.SplitDocuments(docs)
		if err != nil {
			// ä¿å­˜å¤±è´¥æ–‡ä»¶åˆ°å¤±è´¥ç›®å½•
			failureReason := fmt.Sprintf("åˆ‡åˆ†æ–‡æ¡£å¤±è´¥: %v", err)
			if saveErr := s.saveFailedFile(savedPath, fileHeader.Filename, failureReason); saveErr != nil {
				log.Printf("ä¿å­˜å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: %v", saveErr)
				os.Remove(savedPath) // å¦‚æœä¿å­˜å¤±è´¥ï¼Œåˆ é™¤åŸæ–‡ä»¶
			}
			log.Printf("Failed to split document %s: %v", fileHeader.Filename, err)
			results = append(results, FileResult{
				Filename: fileHeader.Filename,
				Success:  false,
				Message:  failureReason,
			})
			failCount++
			continue
		}

		allChunks = append(allChunks, chunks...)
		log.Printf("æ–‡ä»¶ %s å¤„ç†æˆåŠŸï¼Œç”Ÿæˆ %d ä¸ªæ–‡æœ¬å—ï¼Œç´¯è®¡ %d ä¸ªæ–‡æœ¬å—", fileHeader.Filename, len(chunks), len(allChunks))

		// ä¿å­˜æ–‡ä»¶ä¿¡æ¯
		fileInfo := &FileInfo{
			ID:         fileID,
			Filename:   fileHeader.Filename,
			Title:      title,
			Content:    contentPreview,
			Size:       fileSize,
			UploadedAt: time.Now(),
			Chunks:     len(chunks),
		}
		s.files[fileID] = fileInfo

		results = append(results, FileResult{
			Filename: fileHeader.Filename,
			Success:  true,
			Message:  fmt.Sprintf("æˆåŠŸå¤„ç†ï¼Œå…± %d ä¸ªæ–‡æœ¬å—", len(chunks)),
			Chunks:   len(chunks),
			FileID:   fileID,
		})
		successCount++
	}

	// æ·»åŠ åˆ°çŸ¥è¯†åº“ï¼ˆå¦‚æœæœ‰æˆåŠŸçš„æ–‡ä»¶ï¼‰
	var vectorizationError error
	var vectorizedChunks int
	if len(allChunks) > 0 {
		ctx := context.Background()
		log.Printf("å¼€å§‹å‘é‡åŒ– %d ä¸ªæ–‡æœ¬å—...", len(allChunks))
		if err := s.ragSystem.AddDocuments(ctx, allChunks); err != nil {
			log.Printf("å‘é‡åŒ–å¤±è´¥: %v", err)
			vectorizationError = err

			// å‘é‡åŒ–å¤±è´¥æ—¶ï¼Œå°†æ‰€æœ‰æˆåŠŸå¤„ç†çš„æ–‡ä»¶ç§»åŠ¨åˆ°å¤±è´¥ç›®å½•
			failureReason := fmt.Sprintf("å‘é‡åŒ–å¤±è´¥: %v", err)
			for i := range results {
				result := &results[i]
				if result.Success && result.FileID != "" {
					// æŸ¥æ‰¾å¯¹åº”çš„æ–‡ä»¶è·¯å¾„
					if fileInfo, exists := s.files[result.FileID]; exists {
						// æ„å»ºæ–‡ä»¶è·¯å¾„
						cleanedFilename := strings.ReplaceAll(fileInfo.Filename, "/", "_")
						cleanedFilename = strings.ReplaceAll(cleanedFilename, "\\", "_")
						cleanedFilename = strings.ReplaceAll(cleanedFilename, "..", "_")
						filePath := filepath.Join(s.filesDir, result.FileID+"_"+cleanedFilename)

						// ä¿å­˜å¤±è´¥æ–‡ä»¶
						if saveErr := s.saveFailedFile(filePath, fileInfo.Filename, failureReason); saveErr != nil {
							log.Printf("ä¿å­˜å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: %v", saveErr)
						} else {
							// ä»æ–‡ä»¶åˆ—è¡¨ä¸­åˆ é™¤
							delete(s.files, result.FileID)
							// æ›´æ–°ç»“æœçŠ¶æ€
							result.Success = false
							result.Message = failureReason
							successCount--
							failCount++
						}
					}
				}
			}
		} else {
			log.Printf("å‘é‡åŒ–æˆåŠŸï¼Œå…±å¤„ç† %d ä¸ªæ–‡æœ¬å—", len(allChunks))
			vectorizedChunks = len(allChunks)
		}
	} else {
		log.Printf("æ²¡æœ‰éœ€è¦å‘é‡åŒ–çš„æ–‡æœ¬å—")
	}

	w.Header().Set("Content-Type", "application/json")
	response := map[string]interface{}{
		"success":          true,
		"message":          fmt.Sprintf("å¤„ç†å®Œæˆï¼šæˆåŠŸ %d ä¸ªï¼Œå¤±è´¥ %d ä¸ª", successCount, failCount),
		"totalFiles":       len(files),
		"successCount":     successCount,
		"failCount":        failCount,
		"results":          results,
		"totalChunks":      len(allChunks),
		"vectorizedChunks": vectorizedChunks,
	}

	// å¦‚æœå‘é‡åŒ–å¤±è´¥ï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯
	if vectorizationError != nil {
		response["vectorizationError"] = vectorizationError.Error()
		response["message"] = fmt.Sprintf("å¤„ç†å®Œæˆï¼šæˆåŠŸ %d ä¸ªï¼Œå¤±è´¥ %d ä¸ªã€‚âš ï¸ å‘é‡åŒ–å¤±è´¥: %v", successCount, failCount, vectorizationError)
	}

	json.NewEncoder(w).Encode(response)
}

// handleQuery å¤„ç†æŸ¥è¯¢è¯·æ±‚
func (s *Server) handleQuery(w http.ResponseWriter, r *http.Request) {
	// æ·»åŠ panicæ¢å¤ï¼Œç¡®ä¿å³ä½¿å‘ç”Ÿpanicä¹Ÿä¸ä¼šå¯¼è‡´æœåŠ¡å´©æºƒ
	defer func() {
		if r := recover(); r != nil {
			log.Printf("âš ï¸ handleQueryå‘ç”Ÿpanic: %v, å †æ ˆ: %s", r, getStackTrace())
			// å°è¯•è¿”å›é”™è¯¯å“åº”
			if w.Header().Get("Content-Type") == "" {
				w.Header().Set("Content-Type", "application/json; charset=utf-8")
				w.WriteHeader(http.StatusInternalServerError)
				json.NewEncoder(w).Encode(map[string]interface{}{
					"error":   "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
					"message": "æŸ¥è¯¢å¤„ç†æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯",
				})
			}
		}
	}()
	
	// æå‰è®¾ç½®å“åº”å¤´ï¼Œç¡®ä¿å³ä½¿å‘ç”Ÿé”™è¯¯ä¹Ÿèƒ½æ­£ç¡®è¿”å›
	w.Header().Set("Content-Type", "application/json; charset=utf-8")

	if r.Method != "POST" {
		w.WriteHeader(http.StatusMethodNotAllowed)
		json.NewEncoder(w).Encode(map[string]interface{}{
			"error": "Method not allowed",
		})
		return
	}

	var req struct {
		Question string `json:"question"`
		TopK     int    `json:"topk"`
	}

	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		log.Printf("è§£æè¯·æ±‚ä½“å¤±è´¥: %v", err)
		w.WriteHeader(http.StatusBadRequest)
		json.NewEncoder(w).Encode(map[string]interface{}{
			"error":   "Invalid request",
			"message": "æ— æ³•è§£æè¯·æ±‚ä½“",
		})
		return
	}

	if req.Question == "" {
		w.WriteHeader(http.StatusBadRequest)
		json.NewEncoder(w).Encode(map[string]interface{}{
			"error":   "Question is required",
			"message": "é—®é¢˜ä¸èƒ½ä¸ºç©º",
		})
		return
	}

	if req.TopK == 0 {
		req.TopK = 3
	}

	// åˆ›å»ºä¸´æ—¶RAGå®ä¾‹ç”¨äºæŸ¥è¯¢ï¼ˆä½¿ç”¨æŒ‡å®šçš„topKï¼‰
	tempRAG := rag.NewRAG(s.embedder, s.store, s.llm, req.TopK)

	log.Printf("æ”¶åˆ°æŸ¥è¯¢è¯·æ±‚: %s (topK=%d), å®¢æˆ·ç«¯: %s", req.Question, req.TopK, r.RemoteAddr)

	// ä¼˜åŒ–ï¼šä½¿ç”¨è¯·æ±‚çš„contextï¼Œå¹¶æ·»åŠ è¶…æ—¶æ§åˆ¶ï¼ˆ50ç§’ï¼‰ï¼Œç¡®ä¿è¯·æ±‚å¯ä»¥å–æ¶ˆ
	// å‡å°‘è¶…æ—¶æ—¶é—´ï¼Œé¿å…LLMè°ƒç”¨æ—¶é—´è¿‡é•¿å¯¼è‡´æœåŠ¡è¢«åœæ­¢
	ctx, cancel := context.WithTimeout(r.Context(), 50*time.Second)
	defer cancel()

	// ä½¿ç”¨ QueryWithResults æ–¹æ³•ï¼Œé¿å…é‡å¤æœç´¢
	// æ·»åŠ panicæ¢å¤ï¼Œç¡®ä¿LLMè°ƒç”¨å¤±è´¥ä¸ä¼šå¯¼è‡´æœåŠ¡å´©æºƒ
	var queryResult *rag.QueryResult
	var err error
	func() {
		defer func() {
			if r := recover(); r != nil {
				log.Printf("âš ï¸ QueryWithResultså‘ç”Ÿpanic: %v, å †æ ˆ: %s", r, getStackTrace())
				err = fmt.Errorf("æŸ¥è¯¢å¤„ç†æ—¶å‘ç”Ÿpanic: %v", r)
			}
		}()
		queryResult, err = tempRAG.QueryWithResults(ctx, req.Question)
	}()
	if err != nil {
		log.Printf("æŸ¥è¯¢å¤±è´¥ - é—®é¢˜: %s, é”™è¯¯: %v, é”™è¯¯ç±»å‹: %T, å®¢æˆ·ç«¯: %s", req.Question, err, err, r.RemoteAddr)
		// è¿”å›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
		w.WriteHeader(http.StatusInternalServerError)
		if encodeErr := json.NewEncoder(w).Encode(map[string]interface{}{
			"error":   "æŸ¥è¯¢å¤±è´¥",
			"message": err.Error(),
		}); encodeErr != nil {
			log.Printf("ç¼–ç é”™è¯¯å“åº”å¤±è´¥: %v", encodeErr)
		}
		return
	}
	log.Printf("æŸ¥è¯¢æˆåŠŸï¼Œç­”æ¡ˆé•¿åº¦: %d å­—ç¬¦, ç»“æœæ•°é‡: %d", len(queryResult.Answer), len(queryResult.Results))

	// åˆ†æç­”æ¡ˆä¸­çš„æ ‡æ³¨ï¼Œæ‰¾å‡ºè¢«ä½¿ç”¨çš„æ–‡æ¡£ç‰‡æ®µç¼–å·
	usedIndices := extractUsedAnnotations(queryResult.Answer)

	// æŒ‰æ–‡æ¡£æ¥æºåˆ†ç»„ï¼Œåªè¿”å›è¢«æ ‡æ³¨ä½¿ç”¨çš„æ–‡æ¡£ç‰‡æ®µ
	// ä½¿ç”¨ map æ¥æŒ‰æ–‡æ¡£æ¥æºåˆ†ç»„
	// DocGroup ç±»å‹å·²åœ¨åŒ…çº§åˆ«å®šä¹‰

	// ä¼˜åŒ–ï¼šä½¿ç”¨sync.Mapå’Œå¹¶å‘å¤„ç†æ–‡æ¡£åˆ†ç»„ï¼Œæå‡æ€§èƒ½
	type docProcessResult struct {
		index    int
		result   map[string]interface{}
		groupKey string
		group    *DocGroup
	}

	// ä½¿ç”¨å¸¦ç¼“å†²çš„channelæ”¶é›†å¤„ç†ç»“æœ
	// é™åˆ¶ç¼“å†²åŒºå¤§å°ï¼Œé¿å…å¤§ç»“æœé›†å¯¼è‡´å†…å­˜é—®é¢˜ï¼ˆæœ€å¤š1000ä¸ªç»“æœï¼‰
	const maxChannelBuffer = 1000
	bufferSize := len(queryResult.Results)
	if bufferSize > maxChannelBuffer {
		bufferSize = maxChannelBuffer
	}
	resultChan := make(chan docProcessResult, bufferSize)

	// å¹¶å‘å¤„ç†æ‰€æœ‰æ–‡æ¡£ç‰‡æ®µ
	var wg sync.WaitGroup
	for i, doc := range queryResult.Results {
		// æ£€æŸ¥è¿™ä¸ªæ–‡æ¡£ç‰‡æ®µæ˜¯å¦åœ¨ç­”æ¡ˆä¸­è¢«æ ‡æ³¨ä½¿ç”¨ï¼ˆç´¢å¼•ä»1å¼€å§‹ï¼Œæ‰€ä»¥i+1ï¼‰
		if !usedIndices[i+1] {
			continue
		}

		wg.Add(1)
		go func(idx int, d schema.Document) {
			defer wg.Done()
			defer func() {
				if r := recover(); r != nil {
					log.Printf("âš ï¸ å¤„ç†æ–‡æ¡£ç‰‡æ®µæ—¶å‘ç”Ÿpanic: %v, ç´¢å¼•: %d", r, idx)
				}
			}()

			// ä½¿ç”¨åŸå§‹ç´¢å¼•ï¼ˆidx+1ï¼‰ï¼Œä¸AIç­”æ¡ˆä¸­çš„æ ‡æ³¨ä¿æŒä¸€è‡´
			originalIndex := idx + 1

			// è·å–æ–‡æ¡£æ¥æºä¿¡æ¯
			var docTitle, docSource, sourceType, fileType, fileID string
			if source, ok := d.Metadata["source"].(string); ok {
				docSource = source
				// åˆ¤æ–­æ˜¯æ–‡ä»¶è¿˜æ˜¯URL
				if strings.HasPrefix(source, "http://") || strings.HasPrefix(source, "https://") {
					sourceType = "url"
					docTitle = source // URLç›´æ¥ä½¿ç”¨å®Œæ•´URLä½œä¸ºæ ‡é¢˜
				} else {
					sourceType = "file"
					// ä»æ–‡ä»¶è·¯å¾„ä¸­æå–åŸå§‹æ–‡ä»¶åï¼ˆå»é™¤UUIDå‰ç¼€ï¼‰
					docTitle = extractOriginalFilename(filepath.Base(source))
					// ä»æ–‡ä»¶è·¯å¾„ä¸­æå–fileIDï¼ˆæ ¼å¼ï¼š{fileID}_{åŸæ–‡ä»¶å}ï¼‰
					baseName := filepath.Base(source)
					if idx := strings.Index(baseName, "_"); idx > 0 {
						fileID = baseName[:idx]
					}
					// åˆ¤æ–­æ–‡ä»¶ç±»å‹
					ext := strings.ToLower(filepath.Ext(docTitle))
					if ext != "" {
						fileType = ext[1:] // å»æ‰ç‚¹å·
					}
				}
			}
			// ä¼˜å…ˆä½¿ç”¨file_nameå…ƒæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ä¸”ä¸åŒ…å«UUIDï¼‰
			if fileName, ok := d.Metadata["file_name"].(string); ok && fileName != "" {
				// ä»file_nameä¸­æå–åŸå§‹æ–‡ä»¶åï¼ˆå»é™¤UUIDå‰ç¼€ï¼‰
				originalFileName := extractOriginalFilename(fileName)
				if originalFileName != "" {
					docTitle = originalFileName
				}
				// ä»file_nameä¸­æå–fileID
				if idx := strings.Index(fileName, "_"); idx > 0 {
					fileID = fileName[:idx]
				}
				// åˆ¤æ–­æ–‡ä»¶ç±»å‹
				ext := strings.ToLower(filepath.Ext(originalFileName))
				if ext != "" {
					fileType = ext[1:] // å»æ‰ç‚¹å·
				}
			}
			if docTitle == "" {
				docTitle = "æœªå‘½åæ–‡æ¡£"
			}

			// ç”Ÿæˆé¢„è§ˆï¼ˆå‰200å­—ç¬¦ï¼‰
			preview := d.PageContent
			if len(preview) > 200 {
				preview = preview[:200] + "..."
			}

			// åˆ›å»ºæ–‡æ¡£ç‰‡æ®µç»“æœ
			result := map[string]interface{}{
				"content":     d.PageContent,
				"pageContent": d.PageContent,
				"index":       originalIndex, // ä½¿ç”¨åŸå§‹ç´¢å¼•ï¼Œä¸AIç­”æ¡ˆä¸­çš„æ ‡æ³¨ä¿æŒä¸€è‡´
				"source":      docSource,
				"title":       docTitle,
				"preview":     preview,
			}

			// æŒ‰æ–‡æ¡£æ¥æºåˆ†ç»„
			groupKey := docSource
			if groupKey == "" {
				groupKey = docTitle // å¦‚æœæ²¡æœ‰sourceï¼Œä½¿ç”¨titleä½œä¸ºåˆ†ç»„key
			}

			// åˆ›å»ºæ–‡æ¡£ç»„
			group := &DocGroup{
				DocTitle:   docTitle,
				DocSource:  docSource,
				SourceType: sourceType,
				FileType:   fileType,
				FileID:     fileID,
				Chunks:     []map[string]interface{}{result},
			}

			resultChan <- docProcessResult{
				index:    originalIndex,
				result:   result,
				groupKey: groupKey,
				group:    group,
			}
		}(i, doc)
	}

	// ç­‰å¾…æ‰€æœ‰goroutineå®Œæˆ
	go func() {
		wg.Wait()
		close(resultChan)
	}()

	// æ”¶é›†ç»“æœå¹¶åˆ†ç»„
	docGroupsMap := make(map[string]*DocGroup)
	var searchResults []map[string]interface{} // ä¿ç•™å¹³é“ºæ ¼å¼ä»¥å…¼å®¹æ—§å‰ç«¯

	// ä½¿ç”¨sync.Mapç¡®ä¿å¹¶å‘å®‰å…¨
	var mu sync.Mutex

	// æ”¶é›†æ‰€æœ‰ç»“æœ
	for res := range resultChan {
		mu.Lock()
		// æ·»åŠ åˆ°å¹³é“ºæ ¼å¼ï¼ˆå…¼å®¹æ—§å‰ç«¯ï¼‰
		searchResults = append(searchResults, res.result)

		// æŒ‰æ–‡æ¡£æ¥æºåˆ†ç»„
		if existingGroup, exists := docGroupsMap[res.groupKey]; exists {
			// å¦‚æœç»„å·²å­˜åœ¨ï¼Œæ›´æ–°æ–‡ä»¶ç±»å‹å’Œæ–‡ä»¶IDï¼ˆå¦‚æœå½“å‰æ–‡æ¡£ç‰‡æ®µæœ‰è¿™äº›ä¿¡æ¯ï¼‰
			if res.group.FileType != "" && existingGroup.FileType == "" {
				existingGroup.FileType = res.group.FileType
			}
			if res.group.FileID != "" && existingGroup.FileID == "" {
				existingGroup.FileID = res.group.FileID
			}
			existingGroup.Chunks = append(existingGroup.Chunks, res.result)
		} else {
			// åˆ›å»ºæ–°ç»„
			docGroupsMap[res.groupKey] = res.group
		}
		mu.Unlock()
	}

	// å¯¹searchResultsæŒ‰indexæ’åºï¼Œç¡®ä¿é¡ºåºæ­£ç¡®
	sort.Slice(searchResults, func(i, j int) bool {
		idxI, _ := searchResults[i]["index"].(int)
		idxJ, _ := searchResults[j]["index"].(int)
		return idxI < idxJ
	})

	// å°† map è½¬æ¢ä¸º sliceï¼Œå¹¶æ£€æŸ¥pdfã€wordã€txtæ–‡æ¡£ä¸­æ˜¯å¦åŒ…å«"å…¬å¼€å½¢å¼"å­—çœ¼
	// ä¼˜åŒ–ï¼šå¹¶è¡Œå¤„ç†æ–‡æ¡£æ£€æŸ¥ï¼Œé¿å…ä¸²è¡Œé˜»å¡
	docGroups := make([]DocGroup, 0, len(docGroupsMap))

	// åˆ›å»ºä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥æ£€æŸ¥å•ä¸ªæ–‡æ¡£
	checkPublicForm := func(group *DocGroup) {
		// åªå¯¹pdfã€wordã€txtæ–‡æ¡£æ£€æŸ¥æ˜¯å¦åŒ…å«"å…¬å¼€å½¢å¼ï¼šä¸äºˆå…¬å¼€"æˆ–"å…¬å¼€å½¢å¼ï¼šä¾ç”³è¯·å…¬å¼€"
		fileTypeLower := strings.ToLower(group.FileType)
		if fileTypeLower != "pdf" && fileTypeLower != "doc" && fileTypeLower != "docx" && fileTypeLower != "txt" {
			// å¯¹äºépdf/word/txtæ–‡æ¡£ï¼Œä¸è®¾ç½®HasPublicFormå­—æ®µ
			log.Printf("æ–‡æ¡£ %s (ç±»å‹: %s) ä¸æ˜¯PDF/Word/TXTï¼Œä¸æ£€æŸ¥'å…¬å¼€å½¢å¼'", group.DocTitle, group.FileType)
			return
		}

		// å…ˆæ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰ç»“æœ
		if group.FileID != "" {
			if cached, ok := s.publicFormCache.Load(group.FileID); ok {
				hasPublicForm := cached.(bool)
				if hasPublicForm {
					log.Printf("âœ… ä»ç¼“å­˜è·å–ï¼šæ–‡æ¡£ %s åŒ…å«'å…¬å¼€å½¢å¼'", group.DocTitle)
				} else {
					log.Printf("âœ… ä»ç¼“å­˜è·å–ï¼šæ–‡æ¡£ %s ä¸åŒ…å«'å…¬å¼€å½¢å¼'", group.DocTitle)
				}
				group.HasPublicForm = hasPublicForm
				return
			}
		}

		// ç›´æ¥è¯»å–æ–‡æ¡£çš„æœ€å100ä¸ªå­—ç¬¦è¿›è¡Œæ£€æŸ¥ï¼ˆä¸ä»chunksä¸­è¯»å–ï¼‰
		// å°†ä»»åŠ¡æ”¾å…¥å¼‚æ­¥æ£€æŸ¥é˜Ÿåˆ—ï¼Œå¹¶ç­‰å¾…ä¸€å°æ®µæ—¶é—´çœ‹æ˜¯å¦èƒ½å¿«é€Ÿå®Œæˆ
		if group.FileID != "" {
			// å…ˆæ”¾å…¥é˜Ÿåˆ—
			select {
			case s.checkQueue <- group:
				log.Printf("ğŸ“‹ æ–‡æ¡£ %s å·²åŠ å…¥å¼‚æ­¥æ£€æŸ¥é˜Ÿåˆ—ï¼ˆç›´æ¥è¯»å–æ–‡ä»¶æœ€å100ä¸ªå­—ç¬¦ï¼‰", group.DocTitle)
			default:
				// é˜Ÿåˆ—å·²æ»¡ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­ï¼ˆä¸é˜»å¡ï¼‰
				log.Printf("âš ï¸ æ£€æŸ¥é˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡å¼‚æ­¥æ£€æŸ¥: %s", group.DocTitle)
				group.HasPublicForm = false
				return
			}
			
			// ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼ˆ500msï¼‰ï¼Œçœ‹å¼‚æ­¥æ£€æŸ¥æ˜¯å¦èƒ½å¿«é€Ÿå®Œæˆ
			// è¿™æ ·å¯ä»¥é¿å…ç¬¬ä¸€æ¬¡æŸ¥è¯¢æ—¶æ€»æ˜¯å…è®¸ä¸‹è½½
			time.Sleep(500 * time.Millisecond)
			
			// å†æ¬¡æ£€æŸ¥ç¼“å­˜ï¼Œçœ‹å¼‚æ­¥æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
			if cached, ok := s.publicFormCache.Load(group.FileID); ok {
				hasPublicForm := cached.(bool)
				if hasPublicForm {
					log.Printf("âœ… ç­‰å¾…åä»ç¼“å­˜è·å–ï¼šæ–‡æ¡£ %s åŒ…å«'å…¬å¼€å½¢å¼'", group.DocTitle)
				} else {
					log.Printf("âœ… ç­‰å¾…åä»ç¼“å­˜è·å–ï¼šæ–‡æ¡£ %s ä¸åŒ…å«'å…¬å¼€å½¢å¼'", group.DocTitle)
				}
				group.HasPublicForm = hasPublicForm
			} else {
				// å¦‚æœè¿˜æ²¡å®Œæˆï¼Œå…ˆå…è®¸ä¸‹è½½ï¼ˆå¼‚æ­¥æ£€æŸ¥ä¼šæ›´æ–°ç¼“å­˜ï¼Œä¸‹æ¬¡æŸ¥è¯¢æ—¶ä¼šä½¿ç”¨ï¼‰
				log.Printf("â³ æ–‡æ¡£ %s å¼‚æ­¥æ£€æŸ¥å°šæœªå®Œæˆï¼Œå…ˆå…è®¸ä¸‹è½½ï¼ˆä¸‹æ¬¡æŸ¥è¯¢æ—¶ä¼šä½¿ç”¨ç¼“å­˜ç»“æœï¼‰", group.DocTitle)
				group.HasPublicForm = false
			}
		} else {
			// æ²¡æœ‰FileIDï¼Œæ— æ³•æ£€æŸ¥ï¼Œé»˜è®¤å…è®¸ä¸‹è½½
			group.HasPublicForm = false
		}
	}

	// å¹¶è¡Œå¤„ç†æ‰€æœ‰æ–‡æ¡£æ£€æŸ¥
	type checkResult struct {
		groupKey string // ä½¿ç”¨docSourceä½œä¸ºå”¯ä¸€æ ‡è¯†
		group    *DocGroup
	}

	// é™åˆ¶channelç¼“å†²åŒºå¤§å°ï¼Œé¿å…å†…å­˜é—®é¢˜
	docGroupsCount := len(docGroupsMap)
	const maxCheckBuffer = 100
	checkBufferSize := docGroupsCount
	if checkBufferSize > maxCheckBuffer {
		checkBufferSize = maxCheckBuffer
	}
	checkChan := make(chan checkResult, checkBufferSize)

	// ä½¿ç”¨WaitGroupç¡®ä¿æ‰€æœ‰goroutineå®Œæˆ
	var checkWg sync.WaitGroup

	// å¯åŠ¨goroutineå¹¶è¡Œæ£€æŸ¥æ‰€æœ‰æ–‡æ¡£
	// ä¸ºæ¯ä¸ªæ–‡æ¡£æ£€æŸ¥æ·»åŠ è¶…æ—¶æ§åˆ¶ï¼ˆ10ç§’ï¼‰ï¼Œé¿å…å•ä¸ªæ–‡æ¡£æ£€æŸ¥æ—¶é—´è¿‡é•¿å¯¼è‡´æ•´ä½“è¶…æ—¶
	checkCtx, checkCancel := context.WithTimeout(ctx, 10*time.Second)
	defer checkCancel()

	for groupKey, group := range docGroupsMap {
		checkWg.Add(1)
		go func(key string, g *DocGroup) {
			defer checkWg.Done()
			defer func() {
				if r := recover(); r != nil {
					log.Printf("âš ï¸ æ£€æŸ¥æ–‡æ¡£æ—¶å‘ç”Ÿpanic: %v, æ–‡æ¡£: %s", r, g.DocTitle)
					// å‘ç”Ÿpanicæ—¶ï¼Œè®¾ç½®é»˜è®¤å€¼å¹¶ç»§ç»­
					g.HasPublicForm = false
				}
			}()

			// ä½¿ç”¨å¸¦è¶…æ—¶çš„contextæ£€æŸ¥æ–‡æ¡£
			done := make(chan bool, 1)
			go func() {
				defer func() {
					if r := recover(); r != nil {
						log.Printf("âš ï¸ checkPublicFormå‘ç”Ÿpanic: %v, æ–‡æ¡£: %s", r, g.DocTitle)
						g.HasPublicForm = false
					}
					select {
					case done <- true:
					default:
						// channelå·²æ»¡ï¼Œè¯´æ˜å·²ç»å‘é€è¿‡äº†
					}
				}()
				checkPublicForm(g)
			}()
			
			// ç­‰å¾…å®Œæˆæˆ–è¶…æ—¶
			select {
			case <-done:
				// æ£€æŸ¥å®Œæˆ
				log.Printf("âœ… æ–‡æ¡£æ£€æŸ¥å®Œæˆ: %s", g.DocTitle)
			case <-checkCtx.Done():
				// è¶…æ—¶ï¼Œè®¾ç½®é»˜è®¤å€¼
				log.Printf("âš ï¸ æ–‡æ¡£æ£€æŸ¥è¶…æ—¶: %s", g.DocTitle)
				g.HasPublicForm = false
			case <-time.After(8 * time.Second):
				// é¢å¤–è¶…æ—¶ä¿æŠ¤ï¼ˆ8ç§’ï¼‰ï¼Œé¿å…æ— é™ç­‰å¾…
				log.Printf("âš ï¸ æ–‡æ¡£æ£€æŸ¥é¢å¤–è¶…æ—¶ï¼ˆ8ç§’ï¼‰: %s", g.DocTitle)
				g.HasPublicForm = false
			}

			// å‘é€ç»“æœï¼ˆä½¿ç”¨selecté¿å…é˜»å¡ï¼Œæ·»åŠ è¶…æ—¶ï¼‰
			select {
			case checkChan <- checkResult{groupKey: key, group: g}:
				log.Printf("âœ… æ–‡æ¡£æ£€æŸ¥ç»“æœå·²å‘é€: %s", g.DocTitle)
			case <-time.After(2 * time.Second):
				// å‘é€è¶…æ—¶ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­ï¼ˆä¸ä¼šé˜»å¡ï¼‰
				log.Printf("âš ï¸ æ£€æŸ¥ç»“æœchannelå‘é€è¶…æ—¶ï¼ˆ2ç§’ï¼‰ï¼Œè·³è¿‡æ–‡æ¡£: %s", g.DocTitle)
			default:
				// channelå·²æ»¡ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­ï¼ˆä¸ä¼šé˜»å¡ï¼‰
				log.Printf("âš ï¸ æ£€æŸ¥ç»“æœchannelå·²æ»¡ï¼Œè·³è¿‡æ–‡æ¡£: %s", g.DocTitle)
			}
		}(groupKey, group)
	}

	// è®¾ç½®æ”¶é›†ç»“æœçš„è¶…æ—¶æ—¶é—´ï¼ˆ5ç§’ï¼‰ï¼Œç¡®ä¿ä¸ä¼šæ— é™ç­‰å¾…
	// å‡å°‘è¶…æ—¶æ—¶é—´ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
	collectCtx, collectCancel := context.WithTimeout(ctx, 5*time.Second)
	defer collectCancel()

	// æ”¶é›†æ‰€æœ‰æ£€æŸ¥ç»“æœï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
	checkedGroups := make(map[string]*DocGroup, docGroupsCount)
	collectDone := make(chan bool, 1)
	
	// å¯åŠ¨goroutineæ”¶é›†ç»“æœ
	go func() {
		defer func() {
			if r := recover(); r != nil {
				log.Printf("âš ï¸ æ”¶é›†ç»“æœæ—¶å‘ç”Ÿpanic: %v", r)
			}
			select {
			case collectDone <- true:
			default:
				// channelå·²æ»¡ï¼Œè¯´æ˜å·²ç»å‘é€è¿‡äº†
			}
		}()
		for result := range checkChan {
			checkedGroups[result.groupKey] = result.group
			log.Printf("å·²æ”¶é›†æ–‡æ¡£æ£€æŸ¥ç»“æœ: %s", result.group.DocTitle)
		}
		log.Printf("æ”¶é›†goroutineå®Œæˆï¼Œå…±æ”¶é›† %d ä¸ªç»“æœ", len(checkedGroups))
	}()

	// ç­‰å¾…æ‰€æœ‰æ£€æŸ¥å®Œæˆï¼Œç„¶åå…³é—­channel
	// æ·»åŠ è¶…æ—¶æ§åˆ¶ï¼Œé¿å…æŸä¸ªæ£€æŸ¥goroutineå¡ä½å¯¼è‡´æ— é™ç­‰å¾…
	closeDone := make(chan bool, 1)
	go func() {
		defer func() {
			if r := recover(); r != nil {
				log.Printf("âš ï¸ å…³é—­channelæ—¶å‘ç”Ÿpanic: %v", r)
			}
		}()
		// ä½¿ç”¨å¸¦è¶…æ—¶çš„Waitï¼Œé¿å…æ— é™ç­‰å¾…
		waitDone := make(chan bool, 1)
		go func() {
			checkWg.Wait()
			waitDone <- true
		}()
		
		select {
		case <-waitDone:
			log.Printf("æ‰€æœ‰æ£€æŸ¥goroutineå·²å®Œæˆï¼Œå…³é—­channel")
			close(checkChan)
			closeDone <- true
		case <-time.After(5 * time.Second):
			// å¦‚æœ5ç§’å†…æ²¡æœ‰å®Œæˆï¼Œå¼ºåˆ¶å…³é—­channel
			log.Printf("âš ï¸ ç­‰å¾…æ£€æŸ¥goroutineå®Œæˆè¶…æ—¶ï¼ˆ5ç§’ï¼‰ï¼Œå¼ºåˆ¶å…³é—­channelï¼Œå·²æ”¶é›† %d ä¸ªç»“æœ", len(checkedGroups))
			close(checkChan)
			closeDone <- true
		}
	}()

	// ç­‰å¾…æ”¶é›†å®Œæˆæˆ–è¶…æ—¶
	log.Printf("ç­‰å¾…æ–‡æ¡£æ£€æŸ¥ç»“æœæ”¶é›†å®Œæˆ... (è¶…æ—¶æ—¶é—´: 5ç§’, æœŸæœ›æ”¶é›† %d ä¸ªç»“æœ)", docGroupsCount)
	select {
	case <-collectDone:
		// æ”¶é›†å®Œæˆ
		log.Printf("âœ… æ–‡æ¡£æ£€æŸ¥ç»“æœæ”¶é›†å®Œæˆï¼Œå…±æ”¶é›† %d/%d ä¸ªç»“æœ", len(checkedGroups), docGroupsCount)
	case <-collectCtx.Done():
		// è¶…æ—¶ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­å¤„ç†å·²æ”¶é›†çš„ç»“æœ
		log.Printf("âš ï¸ æ–‡æ¡£æ£€æŸ¥ç»“æœæ”¶é›†è¶…æ—¶ï¼ˆ5ç§’ï¼‰ï¼Œå·²æ”¶é›† %d/%d ä¸ªç»“æœ", len(checkedGroups), docGroupsCount)
		// ç¡®ä¿collectDone channelä¸ä¼šé˜»å¡ï¼ˆå¦‚æœgoroutineè¿˜åœ¨è¿è¡Œï¼‰
		select {
		case <-collectDone:
			// goroutineå·²å®Œæˆ
			log.Printf("æ”¶é›†goroutineåœ¨è¶…æ—¶åå®Œæˆ")
		case <-time.After(100 * time.Millisecond):
			// ç­‰å¾…100msï¼Œå¦‚æœè¿˜æ²¡å®Œæˆå°±ç»§ç»­
			log.Printf("âš ï¸ æ”¶é›†goroutineå¯èƒ½å¡ä½ï¼Œç»§ç»­å¤„ç†å·²æ”¶é›†çš„ç»“æœ")
		}
	}
	
	// ç­‰å¾…channelå…³é—­goroutineå®Œæˆï¼ˆæœ€å¤šç­‰å¾…1ç§’ï¼‰
	log.Printf("ç­‰å¾…channelå…³é—­goroutineå®Œæˆ...")
	select {
	case <-closeDone:
		log.Printf("âœ… channelå…³é—­goroutineå·²å®Œæˆ")
	case <-time.After(1 * time.Second):
		log.Printf("âš ï¸ channelå…³é—­goroutineè¶…æ—¶ï¼Œç»§ç»­å¤„ç†")
	}

	// å¦‚æœæœ‰äº›æ–‡æ¡£æ²¡æœ‰æ”¶åˆ°ç»“æœï¼ˆå¯èƒ½å› ä¸ºchannelæ»¡äº†ï¼‰ï¼Œä½¿ç”¨åŸå§‹group
	if len(checkedGroups) < docGroupsCount {
		log.Printf("âš ï¸ è­¦å‘Šï¼šåªæ”¶åˆ° %d/%d ä¸ªæ–‡æ¡£çš„æ£€æŸ¥ç»“æœ", len(checkedGroups), docGroupsCount)
	}
	
	// ç¡®ä¿æ‰€æœ‰goroutineå®Œæˆï¼Œé¿å…åœ¨æ„å»ºå“åº”æ—¶å‡ºç°é—®é¢˜
	log.Printf("ç­‰å¾…goroutineæ¸…ç†å®Œæˆ...")
	// ç­‰å¾…checkWgå®Œæˆï¼Œç¡®ä¿æ‰€æœ‰æ£€æŸ¥goroutineéƒ½å·²ç»“æŸ
	done := make(chan bool, 1)
	go func() {
		checkWg.Wait()
		done <- true
	}()
	
	select {
	case <-done:
		log.Printf("âœ… æ‰€æœ‰æ£€æŸ¥goroutineå·²å®Œæˆ")
	case <-time.After(2 * time.Second):
		log.Printf("âš ï¸ ç­‰å¾…goroutineå®Œæˆè¶…æ—¶ï¼Œç»§ç»­å¤„ç†")
	}
	
	log.Printf("å¼€å§‹æ„å»ºå“åº”æ•°æ®...")

	// æŒ‰åŸå§‹é¡ºåºæ·»åŠ åˆ°docGroups
	log.Printf("å¼€å§‹æ„å»ºå“åº”æ•°æ®ï¼ŒdocGroupsMapæ•°é‡: %d, checkedGroupsæ•°é‡: %d", len(docGroupsMap), len(checkedGroups))
	defer func() {
		if r := recover(); r != nil {
			log.Printf("âš ï¸ æ„å»ºå“åº”æ•°æ®æ—¶å‘ç”Ÿpanic: %v, å †æ ˆ: %s", r, getStackTrace())
		}
	}()
	
	for groupKey, group := range docGroupsMap {
		if checkedGroup, exists := checkedGroups[groupKey]; exists {
			docGroups = append(docGroups, *checkedGroup)
		} else {
			// å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹group
			docGroups = append(docGroups, *group)
		}
	}
	log.Printf("docGroupsæ„å»ºå®Œæˆï¼Œå…± %d ä¸ªæ–‡æ¡£ç»„", len(docGroups))

	// æ„å»ºå“åº”æ•°æ®
	// é™åˆ¶å“åº”å¤§å°ï¼Œé¿å…å†…å­˜æº¢å‡ºå’Œ502é”™è¯¯
	// å¦‚æœdocGroupså¤ªå¤§ï¼Œåªè¿”å›å‰50ä¸ª
	const maxDocGroups = 50
	limitedDocGroups := docGroups
	if len(docGroups) > maxDocGroups {
		log.Printf("âš ï¸ æ–‡æ¡£ç»„æ•°é‡è¿‡å¤š (%d > %d)ï¼Œåªè¿”å›å‰ %d ä¸ª", len(docGroups), maxDocGroups, maxDocGroups)
		limitedDocGroups = docGroups[:maxDocGroups]
	}
	
	// é™åˆ¶æ¯ä¸ªæ–‡æ¡£ç»„çš„chunksæ•°é‡ï¼Œé¿å…å“åº”è¿‡å¤§
	// åŒæ—¶é™åˆ¶æ¯ä¸ªchunkçš„å†…å®¹é•¿åº¦ï¼Œé¿å…å•ä¸ªchunkè¿‡å¤§
	const maxChunksPerGroup = 20
	const maxChunkContentLength = 2000 // æ¯ä¸ªchunkæœ€å¤š2000å­—ç¬¦
	
	totalChunksBefore := 0
	for i := range limitedDocGroups {
		totalChunksBefore += len(limitedDocGroups[i].Chunks)
		
		// é™åˆ¶chunksæ•°é‡
		if len(limitedDocGroups[i].Chunks) > maxChunksPerGroup {
			log.Printf("âš ï¸ æ–‡æ¡£ %s çš„chunksæ•°é‡è¿‡å¤š (%d > %d)ï¼Œåªè¿”å›å‰ %d ä¸ª", limitedDocGroups[i].DocTitle, len(limitedDocGroups[i].Chunks), maxChunksPerGroup, maxChunksPerGroup)
			limitedDocGroups[i].Chunks = limitedDocGroups[i].Chunks[:maxChunksPerGroup]
		}
		
		// é™åˆ¶æ¯ä¸ªchunkçš„å†…å®¹é•¿åº¦
		for j := range limitedDocGroups[i].Chunks {
			chunk := limitedDocGroups[i].Chunks[j]
			if content, ok := chunk["content"].(string); ok && len(content) > maxChunkContentLength {
				chunk["content"] = content[:maxChunkContentLength] + "..."
			}
			if pageContent, ok := chunk["pageContent"].(string); ok && len(pageContent) > maxChunkContentLength {
				chunk["pageContent"] = pageContent[:maxChunkContentLength] + "..."
			}
		}
	}
	totalChunksAfter := 0
	for _, g := range limitedDocGroups {
		totalChunksAfter += len(g.Chunks)
	}
	log.Printf("å“åº”æ•°æ®é™åˆ¶å®Œæˆï¼Œæ–‡æ¡£ç»„æ•°: %d, æ€»chunksæ•°: %d -> %d", len(limitedDocGroups), totalChunksBefore, totalChunksAfter)
	
	// æ„å»ºå“åº”æ•°æ®ï¼Œæ·»åŠ é”™è¯¯å¤„ç†
	var response map[string]interface{}
	func() {
		defer func() {
			if r := recover(); r != nil {
				log.Printf("âš ï¸ æ„å»ºresponse mapæ—¶å‘ç”Ÿpanic: %v, å †æ ˆ: %s", r, getStackTrace())
				// ä½¿ç”¨ç®€åŒ–çš„å“åº”
				response = map[string]interface{}{
					"answer":    queryResult.Answer,
					"results":   []map[string]interface{}{}, // ç©ºç»“æœ
					"docGroups": []DocGroup{},               // ç©ºæ–‡æ¡£ç»„
				}
			}
		}()
		response = map[string]interface{}{
			"answer":    queryResult.Answer,
			"results":   searchResults, // å¹³é“ºæ ¼å¼ï¼ˆå…¼å®¹æ—§å‰ç«¯ï¼‰
			"docGroups": limitedDocGroups,     // æŒ‰æ–‡æ¡£åˆ†ç»„çš„æ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰
		}
	}()
	log.Printf("å“åº”æ•°æ®æ„å»ºå®Œæˆï¼Œå‡†å¤‡ç¼–ç JSONï¼Œansweré•¿åº¦: %d, resultsæ•°é‡: %d, docGroupsæ•°é‡: %d", len(queryResult.Answer), len(searchResults), len(limitedDocGroups))

	// è®¾ç½®å“åº”å¤´ï¼Œç¡®ä¿å³ä½¿ç¼–ç å¤±è´¥ä¹Ÿèƒ½æ­£ç¡®è¿”å›
	w.Header().Set("Content-Type", "application/json; charset=utf-8")
	w.Header().Set("Cache-Control", "no-cache, no-store, must-revalidate")

	// æ£€æŸ¥contextæ˜¯å¦å·²å–æ¶ˆï¼ˆè¶…æ—¶ï¼‰
	if ctx.Err() != nil {
		log.Printf("âš ï¸ è¯·æ±‚contextå·²å–æ¶ˆ: %v, é—®é¢˜: %s", ctx.Err(), req.Question)
		// å¦‚æœcontextå·²å–æ¶ˆï¼Œå°è¯•è¿”å›é”™è¯¯å“åº”
		if w.Header().Get("Content-Type") == "" {
			w.Header().Set("Content-Type", "application/json; charset=utf-8")
		}
		w.WriteHeader(http.StatusRequestTimeout)
		fmt.Fprintf(w, `{"error":"è¯·æ±‚è¶…æ—¶","message":"å¤„ç†æ—¶é—´è¿‡é•¿ï¼Œè¯·æ±‚å·²è¶…æ—¶"}`)
		return
	}
	
	// è®°å½•å“åº”å¤§å°ï¼Œç”¨äºç›‘æ§
	responseSize := len(queryResult.Answer) + len(limitedDocGroups)*100 // ç²—ç•¥ä¼°ç®—
	log.Printf("å‡†å¤‡å‘é€å“åº”ï¼Œç­”æ¡ˆé•¿åº¦: %d å­—ç¬¦, æ–‡æ¡£ç»„æ•°: %d, ä¼°ç®—å“åº”å¤§å°: %d å­—èŠ‚", len(queryResult.Answer), len(limitedDocGroups), responseSize)
	
	// æ£€æŸ¥å®¢æˆ·ç«¯è¿æ¥æ˜¯å¦å·²å…³é—­
	if r.Context().Err() != nil {
		log.Printf("âš ï¸ å®¢æˆ·ç«¯è¿æ¥å·²å…³é—­: %v, é—®é¢˜: %s", r.Context().Err(), req.Question)
		return
	}
	
	// ç¼–ç å“åº”ï¼Œç¡®ä¿é”™è¯¯å¤„ç†
	// ä½¿ç”¨ç¼“å†²å†™å…¥ï¼Œé¿å…å¤§å“åº”å¯¼è‡´é—®é¢˜
	log.Printf("å¼€å§‹ç¼–ç JSONå“åº”...")
	defer func() {
		if r := recover(); r != nil {
			log.Printf("âš ï¸ ç¼–ç å“åº”æ—¶å‘ç”Ÿpanic: %v, å †æ ˆ: %s", r, getStackTrace())
			// å°è¯•è¿”å›é”™è¯¯å“åº”
			if w.Header().Get("Content-Type") == "" {
				w.Header().Set("Content-Type", "application/json; charset=utf-8")
			}
			w.WriteHeader(http.StatusInternalServerError)
			fmt.Fprintf(w, `{"error":"å“åº”ç¼–ç å¤±è´¥","message":"æœåŠ¡å™¨å¤„ç†å“åº”æ—¶å‡ºé”™"}`)
			if flusher, ok := w.(http.Flusher); ok {
				flusher.Flush()
			}
		}
	}()
	
	encoder := json.NewEncoder(w)
	encoder.SetIndent("", "") // ä¸æ ¼å¼åŒ–ï¼Œå‡å°‘å“åº”å¤§å°
	
	if err := encoder.Encode(response); err != nil {
		log.Printf("âš ï¸ ç¼–ç æŸ¥è¯¢å“åº”å¤±è´¥: %v, é—®é¢˜: %s, é”™è¯¯ç±»å‹: %T", err, req.Question, err)
		// å¦‚æœç¼–ç å¤±è´¥ï¼Œå°è¯•è¿”å›ä¸€ä¸ªç®€å•çš„é”™è¯¯å“åº”
		// æ³¨æ„ï¼šæ­¤æ—¶å“åº”å¤´å¯èƒ½å·²ç»éƒ¨åˆ†å†™å…¥ï¼Œä½†è¿™æ˜¯æœ€åçš„å°è¯•
		if w.Header().Get("Content-Type") == "" {
			w.Header().Set("Content-Type", "application/json; charset=utf-8")
		}
		// æ£€æŸ¥æ˜¯å¦å·²ç»å†™å…¥çŠ¶æ€ç ï¼ˆé¿å…é‡å¤å†™å…¥ï¼‰
		w.WriteHeader(http.StatusInternalServerError)
		fmt.Fprintf(w, `{"error":"å“åº”ç¼–ç å¤±è´¥","message":"æœåŠ¡å™¨å¤„ç†å“åº”æ—¶å‡ºé”™"}`)
		if flusher, ok := w.(http.Flusher); ok {
			flusher.Flush()
		}
		return
	}
	
	log.Printf("JSONç¼–ç å®Œæˆï¼Œå‡†å¤‡åˆ·æ–°å“åº”...")
	
	// å°è¯•åˆ·æ–°å“åº”ï¼ˆå¦‚æœæ”¯æŒï¼‰ï¼Œç¡®ä¿æ•°æ®åŠæ—¶å‘é€ï¼Œé¿å…è¶…æ—¶å¯¼è‡´502
	if flusher, ok := w.(http.Flusher); ok {
		flusher.Flush()
		log.Printf("âœ… å“åº”å·²åˆ·æ–°ï¼Œç¡®ä¿æ•°æ®åŠæ—¶å‘é€")
	}

	log.Printf("âœ… æŸ¥è¯¢å“åº”å·²æˆåŠŸå‘é€ï¼Œç­”æ¡ˆé•¿åº¦: %d å­—ç¬¦, æ–‡æ¡£ç»„æ•°: %d", len(queryResult.Answer), len(limitedDocGroups))
}

// loadDocumentLastPart åŠ è½½PDFæˆ–Wordæ–‡æ¡£çš„æœ€åéƒ¨åˆ†ï¼ˆåªåŠ è½½æœ€åå‡ ä¸ªå­—ç¬¦ï¼‰
// é¿å…åŠ è½½æ•´ä¸ªæ–‡æ¡£ï¼ŒèŠ‚çœå†…å­˜å’ŒCPU
// æ³¨æ„ï¼šè™½ç„¶æˆ‘ä»¬åªä¿ç•™æœ€åå‡ ä¸ªå­—ç¬¦ï¼Œä½†åº•å±‚çš„fileLoader.Load()ä»ä¼šè§£ææ•´ä¸ªæ–‡æ¡£
// è¿™æ˜¯PDF/Wordè§£æåº“çš„é™åˆ¶ï¼Œæ— æ³•é¿å…ã€‚ä½†æˆ‘ä»¬å·²ç»é™åˆ¶äº†å†…å­˜ä½¿ç”¨
// maxChars: æœ€å¤šåŠ è½½çš„å­—ç¬¦æ•°ï¼ˆé»˜è®¤100ï¼‰
func loadDocumentLastPart(filePath string, fileType string, maxChars int) (string, error) {
	if maxChars <= 0 {
		maxChars = 100 // é»˜è®¤åªåŠ è½½æœ€å100ä¸ªå­—ç¬¦
	}
	
	// åˆ›å»ºå¸¦è¶…æ—¶çš„contextï¼ˆ1.5ç§’ï¼‰ï¼Œé¿å…å¤§æ–‡ä»¶åŠ è½½æ—¶é—´è¿‡é•¿
	// è¿›ä¸€æ­¥å‡å°‘è¶…æ—¶æ—¶é—´ï¼Œæœ€å°åŒ–CPUå ç”¨
	ctx, cancel := context.WithTimeout(context.Background(), 1500*time.Millisecond)
	defer cancel()

	// åœ¨goroutineä¸­åŠ è½½æ–‡æ¡£ï¼Œä»¥ä¾¿å¯ä»¥è¶…æ—¶å–æ¶ˆ
	type loadResult struct {
		docs []schema.Document
		err  error
	}
	resultChan := make(chan loadResult, 1)

	// ä½¿ç”¨goroutineåŠ è½½ï¼Œé¿å…é˜»å¡
	go func() {
		defer func() {
			if r := recover(); r != nil {
				log.Printf("âš ï¸ loadDocumentLastPartåŠ è½½æ–‡æ¡£æ—¶å‘ç”Ÿpanic: %v", r)
				resultChan <- loadResult{err: fmt.Errorf("åŠ è½½æ–‡æ¡£æ—¶å‘ç”Ÿpanic: %v", r)}
			}
		}()
		fileLoader := loader.NewFileLoader()
		docs, err := fileLoader.Load(filePath)
		resultChan <- loadResult{docs: docs, err: err}
	}()

	var docs []schema.Document
	var err error

	select {
	case result := <-resultChan:
		docs = result.docs
		err = result.err
	case <-ctx.Done():
		// è¶…æ—¶ï¼Œè¿”å›é”™è¯¯ï¼Œé¿å…ç»§ç»­å ç”¨å†…å­˜å’ŒCPU
		log.Printf("âš ï¸ åŠ è½½æ–‡æ¡£è¶…æ—¶ï¼ˆè¶…è¿‡1.5ç§’ï¼‰: %s", filePath)
		return "", fmt.Errorf("åŠ è½½æ–‡æ¡£è¶…æ—¶ï¼ˆè¶…è¿‡1.5ç§’ï¼‰")
	}

	if err != nil {
		return "", fmt.Errorf("åŠ è½½æ–‡æ¡£å¤±è´¥: %w", err)
	}

	if len(docs) == 0 {
		return "", fmt.Errorf("æ–‡æ¡£ä¸ºç©º")
	}

	// åªå–æœ€åä¸€é¡µ/æœ€åä¸€ä¸ªæ–‡æ¡£çš„æœ€åéƒ¨åˆ†
	// å¯¹äºPDFï¼Œé€šå¸¸æ¯ä¸ªæ–‡æ¡£ä»£è¡¨ä¸€é¡µï¼Œæˆ‘ä»¬åªå–æœ€åä¸€é¡µ
	// å¯¹äºWordï¼Œé€šå¸¸åªæœ‰ä¸€ä¸ªæ–‡æ¡£ï¼Œæˆ‘ä»¬åªå–æœ€åéƒ¨åˆ†
	lastDoc := docs[len(docs)-1]
	content := lastDoc.PageContent

	// åªå–æœ€åmaxCharsä¸ªå­—ç¬¦
	if len(content) > maxChars {
		content = content[len(content)-maxChars:]
	}

	return content, nil
}

// readFileLastBytes è¯»å–æ–‡ä»¶çš„æœ€åNä¸ªå­—èŠ‚ï¼ˆå°è¯•æŒ‰UTF-8è§£ç ï¼‰
func readFileLastBytes(filePath string, maxBytes int) (string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return "", err
	}
	defer file.Close()

	// è·å–æ–‡ä»¶å¤§å°
	fileInfo, err := file.Stat()
	if err != nil {
		return "", err
	}

	fileSize := fileInfo.Size()
	if fileSize == 0 {
		return "", nil
	}

	// è®¡ç®—è¦è¯»å–çš„å­—èŠ‚æ•°
	bytesToRead := int64(maxBytes)
	if fileSize < bytesToRead {
		bytesToRead = fileSize
	}

	// å®šä½åˆ°æ–‡ä»¶æœ«å°¾
	_, err = file.Seek(fileSize-bytesToRead, 0)
	if err != nil {
		return "", err
	}

	// è¯»å–æœ€åNä¸ªå­—èŠ‚
	buffer := make([]byte, bytesToRead)
	n, err := file.Read(buffer)
	if err != nil && err != io.EOF {
		return "", err
	}

	// å°è¯•æŒ‰UTF-8è§£ç 
	content := string(buffer[:n])
	return content, nil
}

// checkPublicFormInContent æ£€æŸ¥å†…å®¹ä¸­æ˜¯å¦åŒ…å«"å…¬å¼€å½¢å¼"ç›¸å…³å­—æ ·
// æ”¯æŒå…¨è§’å†’å·ï¼ˆï¼šï¼‰å’ŒåŠè§’å†’å·ï¼ˆ:ï¼‰ï¼Œä»¥åŠå¯èƒ½çš„ç©ºæ ¼å’Œæ¢è¡Œ
// å¦‚æœå†…å®¹ä¸­åŒ…å«"å…¬å¼€å½¢å¼"å››ä¸ªå­—ï¼Œå°±è®¤ä¸ºåŒ…å«ï¼ˆå› ä¸ºç”¨æˆ·éœ€æ±‚æ˜¯æ£€æŸ¥æ˜¯å¦æœ‰"å…¬å¼€å½¢å¼"ï¼‰
func checkPublicFormInContent(content string) bool {
	if content == "" {
		return false
	}

	// é¦–å…ˆæ£€æŸ¥æ˜¯å¦åŒ…å«"å…¬å¼€å½¢å¼"å››ä¸ªå­—ï¼ˆè¿™æ˜¯æœ€åŸºæœ¬çš„æ£€æŸ¥ï¼‰
	if strings.Contains(content, "å…¬å¼€å½¢å¼") {
		return true
	}

	// å¦‚æœç›´æ¥åŒ…å«"å…¬å¼€å½¢å¼"å››ä¸ªå­—ï¼Œå·²ç»è¿”å›true
	// ä¸‹é¢çš„ä»£ç æ˜¯ä¸ºäº†æ›´ç²¾ç¡®çš„åŒ¹é…ï¼Œä½†ä¸Šé¢çš„æ£€æŸ¥å·²ç»è¶³å¤Ÿäº†
	// å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
	containsNotPublicFull := strings.Contains(content, "å…¬å¼€å½¢å¼ï¼šä¸äºˆå…¬å¼€")
	containsApplyPublicFull := strings.Contains(content, "å…¬å¼€å½¢å¼ï¼šä¾ç”³è¯·å…¬å¼€")
	containsNotPublicFull2 := strings.Contains(content, "å…¬å¼€å½¢å¼ï¼šä¸å…¬å¼€")
	containsNotPublicHalf := strings.Contains(content, "å…¬å¼€å½¢å¼:ä¸äºˆå…¬å¼€")
	containsApplyPublicHalf := strings.Contains(content, "å…¬å¼€å½¢å¼:ä¾ç”³è¯·å…¬å¼€")
	containsNotPublicHalf2 := strings.Contains(content, "å…¬å¼€å½¢å¼:ä¸å…¬å¼€")

	if containsNotPublicFull || containsApplyPublicFull || containsNotPublicFull2 ||
		containsNotPublicHalf || containsApplyPublicHalf || containsNotPublicHalf2 {
		return true
	}

	// å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆå…è®¸å†’å·å‰åæœ‰ç©ºæ ¼ï¼‰
	normalizedContent := strings.ReplaceAll(content, " ", "")
	normalizedContent = strings.ReplaceAll(normalizedContent, "\n", "")
	normalizedContent = strings.ReplaceAll(normalizedContent, "\r", "")
	normalizedContent = strings.ReplaceAll(normalizedContent, "\t", "")

	// åœ¨è§„èŒƒåŒ–åçš„å†…å®¹ä¸­ä¹Ÿæ£€æŸ¥"å…¬å¼€å½¢å¼"å››ä¸ªå­—
	if strings.Contains(normalizedContent, "å…¬å¼€å½¢å¼") {
		return true
	}

	containsNotPublicFull = strings.Contains(normalizedContent, "å…¬å¼€å½¢å¼ï¼šä¸äºˆå…¬å¼€")
	containsApplyPublicFull = strings.Contains(normalizedContent, "å…¬å¼€å½¢å¼ï¼šä¾ç”³è¯·å…¬å¼€")
	containsNotPublicFull2 = strings.Contains(normalizedContent, "å…¬å¼€å½¢å¼ï¼šä¸å…¬å¼€")
	containsNotPublicHalf = strings.Contains(normalizedContent, "å…¬å¼€å½¢å¼:ä¸äºˆå…¬å¼€")
	containsApplyPublicHalf = strings.Contains(normalizedContent, "å…¬å¼€å½¢å¼:ä¾ç”³è¯·å…¬å¼€")
	containsNotPublicHalf2 = strings.Contains(normalizedContent, "å…¬å¼€å½¢å¼:ä¸å…¬å¼€")

	return containsNotPublicFull || containsApplyPublicFull || containsNotPublicFull2 ||
		containsNotPublicHalf || containsApplyPublicHalf || containsNotPublicHalf2
}

// extractOriginalFilename ä»æ–‡ä»¶åä¸­æå–åŸå§‹æ–‡ä»¶åï¼Œå»é™¤UUIDå‰ç¼€
// æ ¼å¼ï¼š{UUID}_{åŸæ–‡ä»¶å} -> {åŸæ–‡ä»¶å}
func extractOriginalFilename(filename string) string {
	if filename == "" {
		return ""
	}

	// UUIDæ ¼å¼ï¼šxxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
	// æŸ¥æ‰¾ç¬¬ä¸€ä¸ªä¸‹åˆ’çº¿ï¼Œå¦‚æœä¸‹åˆ’çº¿å‰æ˜¯UUIDæ ¼å¼ï¼Œåˆ™æå–ä¸‹åˆ’çº¿åçš„éƒ¨åˆ†
	// UUIDé•¿åº¦ï¼š36ä¸ªå­—ç¬¦ï¼ˆ32ä¸ªåå…­è¿›åˆ¶å­—ç¬¦ + 4ä¸ªè¿å­—ç¬¦ï¼‰
	underscoreIndex := strings.Index(filename, "_")
	if underscoreIndex > 0 {
		// æ£€æŸ¥ä¸‹åˆ’çº¿å‰çš„éƒ¨åˆ†æ˜¯å¦æ˜¯UUIDæ ¼å¼ï¼ˆ36ä¸ªå­—ç¬¦ï¼‰
		prefix := filename[:underscoreIndex]
		if len(prefix) == 36 && strings.Contains(prefix, "-") {
			// éªŒè¯æ˜¯å¦æ˜¯UUIDæ ¼å¼ï¼ˆåŒ…å«4ä¸ªè¿å­—ç¬¦ï¼‰
			parts := strings.Split(prefix, "-")
			if len(parts) == 5 {
				// æå–ä¸‹åˆ’çº¿åçš„éƒ¨åˆ†ä½œä¸ºåŸå§‹æ–‡ä»¶å
				originalName := filename[underscoreIndex+1:]
				if originalName != "" {
					return originalName
				}
			}
		}
	}

	// å¦‚æœæ²¡æœ‰UUIDå‰ç¼€ï¼Œç›´æ¥è¿”å›åŸæ–‡ä»¶å
	return filename
}

// extractUsedAnnotations ä»ç­”æ¡ˆä¸­æå–ä½¿ç”¨çš„æ ‡æ³¨ç¼–å·
// è¿”å›ä¸€ä¸ªmapï¼Œkeyæ˜¯æ–‡æ¡£ç‰‡æ®µç¼–å·ï¼ˆä»1å¼€å§‹ï¼‰ï¼Œvalueè¡¨ç¤ºæ˜¯å¦è¢«ä½¿ç”¨
func extractUsedAnnotations(answer string) map[int]bool {
	used := make(map[int]bool)

	// åœ†åœˆæ•°å­—æ˜ å°„ï¼šâ‘ =1, â‘¡=2, â‘¢=3, ...
	circleNumbers := []string{"â‘ ", "â‘¡", "â‘¢", "â‘£", "â‘¤", "â‘¥", "â‘¦", "â‘§", "â‘¨", "â‘©"}

	// æ£€æŸ¥ç­”æ¡ˆä¸­æ˜¯å¦åŒ…å«è¿™äº›æ ‡æ³¨
	for i, circleNum := range circleNumbers {
		if strings.Contains(answer, circleNum) {
			used[i+1] = true
		}
	}

	return used
}

// isSystemFile æ£€æŸ¥æ˜¯å¦æ˜¯ç³»ç»Ÿæ–‡ä»¶
func isSystemFile(filename string) bool {
	// macOS ç³»ç»Ÿæ–‡ä»¶
	if filename == ".DS_Store" {
		return true
	}
	// macOS èµ„æºåˆ†å‰æ–‡ä»¶
	if strings.HasPrefix(filename, "._") {
		return true
	}
	// Windows ç³»ç»Ÿæ–‡ä»¶
	if strings.HasPrefix(filename, "~$") {
		return true
	}
	// Linux/Unix éšè—æ–‡ä»¶ï¼ˆä½†å…è®¸ .å¼€å¤´çš„æ­£å¸¸æ–‡ä»¶ï¼Œåªè¿‡æ»¤ç³»ç»Ÿæ–‡ä»¶ï¼‰
	if filename == ".gitkeep" || filename == ".gitignore" {
		return true
	}
	return false
}

// isFileDuplicate æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆé€šè¿‡æ–‡ä»¶åå’Œå¤§å°åˆ¤æ–­ï¼‰
func (s *Server) isFileDuplicate(filename string, size int64) bool {
	// é‡æ–°åŠ è½½æ–‡ä»¶åˆ—è¡¨ä»¥ç¡®ä¿æ•°æ®æœ€æ–°
	s.loadFilesFromDisk()

	for _, file := range s.files {
		if file.Filename == filename && file.Size == size {
			return true
		}
	}
	return false
}

// loadFilesFromDisk ä»ç£ç›˜åŠ è½½æ–‡ä»¶åˆ—è¡¨
func (s *Server) loadFilesFromDisk() {
	entries, err := os.ReadDir(s.filesDir)
	if err != nil {
		log.Printf("è¯»å–æ–‡ä»¶ç›®å½•å¤±è´¥: %v", err)
		return
	}

	for _, entry := range entries {
		if entry.IsDir() {
			continue
		}

		// è¿‡æ»¤ç³»ç»Ÿæ–‡ä»¶
		filename := entry.Name()
		if isSystemFile(filename) {
			continue
		}

		info, err := entry.Info()
		if err != nil {
			continue
		}

		// æå–æ–‡ä»¶IDå’ŒåŸæ–‡ä»¶å
		// æ–‡ä»¶åæ ¼å¼å¯èƒ½æ˜¯ï¼š{fileID}{æ‰©å±•å} æˆ– {fileID}_{åŸæ–‡ä»¶å}
		ext := filepath.Ext(entry.Name())
		nameWithoutExt := strings.TrimSuffix(entry.Name(), ext)

		var fileID, originalFilename string
		// æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸‹åˆ’çº¿ï¼ˆæ–°æ ¼å¼ï¼š{fileID}_{åŸæ–‡ä»¶å}ï¼‰
		idx := strings.Index(nameWithoutExt, "_")
		if idx > 0 {
			// æ–°æ ¼å¼ï¼š{fileID}_{åŸæ–‡ä»¶å}
			fileID = nameWithoutExt[:idx]
			originalFilename = nameWithoutExt[idx+1:] + ext
		} else {
			// æ—§æ ¼å¼ï¼š{fileID}{æ‰©å±•å}ï¼Œæ— æ³•æ¢å¤åŸæ–‡ä»¶åï¼Œä½¿ç”¨é»˜è®¤åç§°
			fileID = nameWithoutExt
			originalFilename = "æ–‡ä»¶" + ext // ä½¿ç”¨é»˜è®¤åç§°
		}

		// å¦‚æœæ–‡ä»¶ä¿¡æ¯ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
		if _, exists := s.files[fileID]; !exists {
			title := strings.TrimSuffix(originalFilename, ext)
			s.files[fileID] = &FileInfo{
				ID:         fileID,
				Filename:   originalFilename, // ä½¿ç”¨åŸæ–‡ä»¶åï¼Œè€Œä¸æ˜¯ä¿å­˜çš„æ–‡ä»¶å
				Title:      title,
				Content:    "", // æ— æ³•ä»æ–‡ä»¶ç³»ç»Ÿè·å–å†…å®¹é¢„è§ˆ
				Size:       info.Size(),
				UploadedAt: info.ModTime(),
				Chunks:     0, // æ— æ³•ä»æ–‡ä»¶ç³»ç»Ÿè·å–ï¼Œè®¾ä¸º0
			}
		}
	}

	log.Printf("ä»ç£ç›˜åŠ è½½äº† %d ä¸ªæ–‡ä»¶", len(s.files))
}

// handleFileList è·å–æ–‡ä»¶åˆ—è¡¨
func (s *Server) handleFileList(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	// æ£€æŸ¥ç®¡ç†å‘˜æƒé™
	if !s.checkAdminAuth(r) {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}

	// é‡æ–°ä»ç£ç›˜åŠ è½½æ–‡ä»¶åˆ—è¡¨ï¼ˆç¡®ä¿æ•°æ®æœ€æ–°ï¼‰
	s.loadFilesFromDisk()

	var fileList []*FileInfo
	for _, file := range s.files {
		fileList = append(fileList, file)
	}

	// æŒ‰ä¸Šä¼ æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
	sort.Slice(fileList, func(i, j int) bool {
		return fileList[i].UploadedAt.After(fileList[j].UploadedAt)
	})

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"success": true,
		"data":    fileList,
		"total":   len(fileList),
	})
}

// handleFileCount è·å–æ–‡ä»¶æ•°é‡ï¼ˆæ— éœ€ç®¡ç†å‘˜æƒé™ï¼Œå…¬å¼€æ¥å£ï¼‰
func (s *Server) handleFileCount(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	// é‡æ–°ä»ç£ç›˜åŠ è½½æ–‡ä»¶åˆ—è¡¨ï¼ˆç¡®ä¿æ•°æ®æœ€æ–°ï¼‰
	s.loadFilesFromDisk()

	// è¿‡æ»¤ç³»ç»Ÿæ–‡ä»¶
	var count int
	for _, file := range s.files {
		if !isSystemFile(file.Filename) {
			count++
		}
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"success": true,
		"count":   count,
	})
}

// handleFileDownload ä¸‹è½½æ–‡ä»¶
func (s *Server) handleFileDownload(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	// ä»URLæå–æ–‡ä»¶ID
	path := strings.TrimPrefix(r.URL.Path, "/api/files/")
	if path == "" {
		http.Error(w, "File ID required", http.StatusBadRequest)
		return
	}

	// æŸ¥æ‰¾æ–‡ä»¶ä¿¡æ¯
	fileInfo, exists := s.files[path]
	if !exists {
		http.Error(w, "File not found", http.StatusNotFound)
		return
	}

	// æ„å»ºæ–‡ä»¶è·¯å¾„
	// æ–°æ ¼å¼ï¼š{fileID}_{åŸæ–‡ä»¶å}
	// æ—§æ ¼å¼ï¼š{fileID}{æ‰©å±•å}ï¼ˆå…¼å®¹å¤„ç†ï¼‰
	var filePath string
	newFormatPath := filepath.Join(s.filesDir, path+"_"+fileInfo.Filename)
	oldFormatPath := filepath.Join(s.filesDir, path+filepath.Ext(fileInfo.Filename))

	// ä¼˜å…ˆå°è¯•æ–°æ ¼å¼
	if _, err := os.Stat(newFormatPath); err == nil {
		filePath = newFormatPath
	} else if _, err := os.Stat(oldFormatPath); err == nil {
		// å…¼å®¹æ—§æ ¼å¼
		filePath = oldFormatPath
	} else {
		http.Error(w, "File not found on disk", http.StatusNotFound)
		return
	}

	// æ‰“å¼€æ–‡ä»¶
	file, err := os.Open(filePath)
	if err != nil {
		http.Error(w, fmt.Sprintf("Failed to open file: %v", err), http.StatusInternalServerError)
		return
	}
	defer file.Close()

	// è®¾ç½®å“åº”å¤´
	w.Header().Set("Content-Disposition", fmt.Sprintf("attachment; filename=%s", fileInfo.Filename))
	w.Header().Set("Content-Type", "application/octet-stream")
	w.Header().Set("Content-Length", fmt.Sprintf("%d", fileInfo.Size))

	// å¤åˆ¶æ–‡ä»¶å†…å®¹åˆ°å“åº”
	_, err = io.Copy(w, file)
	if err != nil {
		log.Printf("Failed to send file: %v", err)
	}
}

// handleFileDelete åˆ é™¤æ–‡ä»¶
func (s *Server) handleFileDelete(w http.ResponseWriter, r *http.Request) {
	if r.Method != "DELETE" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	// æ£€æŸ¥ç®¡ç†å‘˜æƒé™
	if !s.checkAdminAuth(r) {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}

	// ä»URLæå–æ–‡ä»¶ID
	path := strings.TrimPrefix(r.URL.Path, "/api/files/")
	if path == "" {
		http.Error(w, "File ID required", http.StatusBadRequest)
		return
	}

	// æŸ¥æ‰¾æ–‡ä»¶ä¿¡æ¯
	fileInfo, exists := s.files[path]
	if !exists {
		http.Error(w, "File not found", http.StatusNotFound)
		return
	}

	// æ„å»ºæ–‡ä»¶è·¯å¾„
	var filePath string
	newFormatPath := filepath.Join(s.filesDir, path+"_"+fileInfo.Filename)
	oldFormatPath := filepath.Join(s.filesDir, path+filepath.Ext(fileInfo.Filename))

	// ä¼˜å…ˆå°è¯•æ–°æ ¼å¼
	if _, err := os.Stat(newFormatPath); err == nil {
		filePath = newFormatPath
	} else if _, err := os.Stat(oldFormatPath); err == nil {
		// å…¼å®¹æ—§æ ¼å¼
		filePath = oldFormatPath
	} else {
		// æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½†ä»ç„¶ä»åˆ—è¡¨ä¸­åˆ é™¤
		log.Printf("æ–‡ä»¶ %s åœ¨ç£ç›˜ä¸Šä¸å­˜åœ¨ï¼Œä»…ä»åˆ—è¡¨ä¸­åˆ é™¤", path)
	}

	// åˆ é™¤ç£ç›˜ä¸Šçš„æ–‡ä»¶
	if filePath != "" {
		if err := os.Remove(filePath); err != nil {
			log.Printf("åˆ é™¤æ–‡ä»¶å¤±è´¥: %v", err)
			// ç»§ç»­æ‰§è¡Œï¼Œå³ä½¿åˆ é™¤æ–‡ä»¶å¤±è´¥ä¹Ÿç»§ç»­åˆ é™¤è®°å½•
		}
	}

	// ä»å†…å­˜ä¸­çš„æ–‡ä»¶åˆ—è¡¨åˆ é™¤
	delete(s.files, path)

	// ä»Qdrantå‘é‡æ•°æ®åº“ä¸­åˆ é™¤ç›¸å…³æ–‡æ¡£
	// é€šè¿‡metadataä¸­çš„sourceå­—æ®µåŒ¹é…æ–‡ä»¶è·¯å¾„
	ctx := context.Background()
	if err := s.deleteDocumentsBySource(ctx, filePath); err != nil {
		log.Printf("ä»å‘é‡æ•°æ®åº“åˆ é™¤æ–‡æ¡£å¤±è´¥: %v", err)
		// å³ä½¿åˆ é™¤å‘é‡æ•°æ®åº“ä¸­çš„æ–‡æ¡£å¤±è´¥ï¼Œä¹Ÿè¿”å›æˆåŠŸï¼ˆå› ä¸ºæ–‡ä»¶å·²åˆ é™¤ï¼‰
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"success": true,
		"message": fmt.Sprintf("æ–‡ä»¶ %s å·²åˆ é™¤", fileInfo.Filename),
	})
}

// deleteDocumentsBySource ä»Qdrantä¸­åˆ é™¤æŒ‡å®šsourceçš„æ–‡æ¡£
func (s *Server) deleteDocumentsBySource(ctx context.Context, sourcePath string) error {
	if sourcePath == "" {
		return nil
	}

	// ä½¿ç”¨Qdrantçš„APIåˆ é™¤æ–‡æ¡£
	// æ³¨æ„ï¼šlangchaingoçš„Qdrantå®ç°å¯èƒ½ä¸ç›´æ¥æ”¯æŒæŒ‰metadataåˆ é™¤
	// è¿™é‡Œæˆ‘ä»¬éœ€è¦ç›´æ¥è°ƒç”¨Qdrantçš„API
	// ç”±äºQdrantçš„åˆ é™¤éœ€è¦point IDï¼Œæˆ‘ä»¬éœ€è¦å…ˆæŸ¥è¯¢æ‰€æœ‰åŒ¹é…çš„pointï¼Œç„¶ååˆ é™¤

	// ç®€åŒ–å®ç°ï¼šç”±äºlangchaingoçš„QdrantåŒ…è£…å™¨ä¸ç›´æ¥æ”¯æŒæŒ‰metadataåˆ é™¤
	// è¿™é‡Œæˆ‘ä»¬åªè®°å½•æ—¥å¿—ï¼Œå®é™…åˆ é™¤å¯ä»¥é€šè¿‡Qdrantçš„APIå®ç°
	// æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥é‡æ–°æ„å»ºæ•´ä¸ªçŸ¥è¯†åº“ï¼ˆåˆ é™¤æ‰€æœ‰ï¼Œç„¶åé‡æ–°æ·»åŠ å…¶ä»–æ–‡ä»¶ï¼‰
	// ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œå…ˆåªåˆ é™¤æ–‡ä»¶ï¼Œå‘é‡æ•°æ®åº“ä¸­çš„æ–‡æ¡£å¯ä»¥ä¿ç•™ï¼ˆä¸å½±å“åŠŸèƒ½ï¼‰

	log.Printf("æ³¨æ„ï¼šå‘é‡æ•°æ®åº“ä¸­çš„æ–‡æ¡£ï¼ˆsource=%sï¼‰éœ€è¦æ‰‹åŠ¨æ¸…ç†æˆ–é€šè¿‡Qdrant APIåˆ é™¤", sourcePath)
	return nil
}

// handleFeedback å¤„ç†æ„è§åé¦ˆæäº¤ï¼Œå°†æ•°æ®å†™å…¥ MySQL
func (s *Server) handleFeedback(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	// å¿…é¡»é…ç½® MySQL æ‰èƒ½ä½¿ç”¨åé¦ˆåŠŸèƒ½
	if s.db == nil {
		http.Error(w, "Feedback database not configured (ç¼ºå°‘ MYSQL_DSN)", http.StatusInternalServerError)
		return
	}

	// è§£æè¡¨å•ï¼ˆåŒ…æ‹¬å¯é€‰å›¾ç‰‡ï¼‰
	if err := r.ParseMultipartForm(10 << 20); err != nil { // 10MB
		http.Error(w, fmt.Sprintf("è§£æè¡¨å•å¤±è´¥: %v", err), http.StatusBadRequest)
		return
	}

	name := strings.TrimSpace(r.FormValue("name"))
	title := strings.TrimSpace(r.FormValue("title"))
	description := strings.TrimSpace(r.FormValue("description"))

	if name == "" || title == "" || description == "" {
		http.Error(w, "å§“åã€æ ‡é¢˜ã€è¯¦ç»†æè¿°ä¸ºå¿…å¡«é¡¹", http.StatusBadRequest)
		return
	}

	// å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰ï¼šä¿å­˜åˆ°æœ¬åœ°ç›®å½•ï¼Œå¹¶åœ¨æ•°æ®åº“ä¸­è®°å½•ç›¸å¯¹è·¯å¾„
	var imagePath sql.NullString
	file, header, err := r.FormFile("image")
	if err == nil && header != nil {
		defer file.Close()

		// åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½•ï¼š./uploads/feedback-images
		imageDir := filepath.Join(s.filesDir, "feedback-images")
		if err := os.MkdirAll(imageDir, 0755); err != nil {
			log.Printf("åˆ›å»ºåé¦ˆå›¾ç‰‡ç›®å½•å¤±è´¥: %v", err)
		} else {
			// ä½¿ç”¨æ—¶é—´æˆ³+åŸå§‹æ–‡ä»¶åï¼Œé¿å…é‡å
			ext := filepath.Ext(header.Filename)
			nameWithoutExt := strings.TrimSuffix(header.Filename, ext)
			nameWithoutExt = strings.ReplaceAll(nameWithoutExt, "/", "_")
			nameWithoutExt = strings.ReplaceAll(nameWithoutExt, "\\", "_")
			nameWithoutExt = strings.ReplaceAll(nameWithoutExt, "..", "_")
			timestamp := time.Now().Format("20060102_150405")
			savedName := fmt.Sprintf("%s_%s%s", timestamp, nameWithoutExt, ext)

			fullPath := filepath.Join(imageDir, savedName)
			out, err := os.Create(fullPath)
			if err != nil {
				log.Printf("ä¿å­˜åé¦ˆå›¾ç‰‡å¤±è´¥: %v", err)
			} else {
				if _, err := io.Copy(out, file); err != nil {
					log.Printf("å†™å…¥åé¦ˆå›¾ç‰‡å¤±è´¥: %v", err)
				} else {
					// åœ¨æ•°æ®åº“ä¸­è®°å½•ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äº backend æ ¹ç›®å½•ï¼‰
					relPath := filepath.ToSlash(filepath.Join("uploads", "feedback-images", savedName))
					imagePath.String = relPath
					imagePath.Valid = true
				}
				out.Close()
			}
		}
	}

	// å†™å…¥ MySQL
	query := `INSERT INTO feedbacks (name, title, description, image, created_at) VALUES (?, ?, ?, ?, ?)`
	_, err = s.db.Exec(query, name, title, description, imagePath, time.Now())
	if err != nil {
		log.Printf("ä¿å­˜åé¦ˆå¤±è´¥: %v", err)
		http.Error(w, fmt.Sprintf("ä¿å­˜åé¦ˆå¤±è´¥: %v", err), http.StatusInternalServerError)
		return
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"success": true,
		"message": "æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼å·²æˆåŠŸä¿å­˜ã€‚",
	})
}

// saveFailedFile ä¿å­˜å¤±è´¥çš„æ–‡ä»¶åˆ°å¤±è´¥ç›®å½•ï¼Œå¹¶è®°å½•å¤±è´¥åŸå› 
func (s *Server) saveFailedFile(filePath, originalFilename, reason string) error {
	// ç¡®ä¿å¤±è´¥ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(s.failedFilesDir, 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºå¤±è´¥æ–‡ä»¶ç›®å½•å¤±è´¥: %v", err)
	}

	ext := filepath.Ext(originalFilename)
	nameWithoutExt := strings.TrimSuffix(originalFilename, ext)

	// æ¸…ç†æ–‡ä»¶åä¸­çš„å±é™©å­—ç¬¦
	cleanedName := strings.ReplaceAll(nameWithoutExt, "/", "_")
	cleanedName = strings.ReplaceAll(cleanedName, "\\", "_")
	cleanedName = strings.ReplaceAll(cleanedName, "..", "_")

	// ä½¿ç”¨åŸæ–‡ä»¶åï¼ˆæ¸…ç†å±é™©å­—ç¬¦åï¼‰
	failedFilename := cleanedName + ext
	failedPath := filepath.Join(s.failedFilesDir, failedFilename)

	// å¦‚æœæ–‡ä»¶åå·²å­˜åœ¨ï¼Œæ·»åŠ åºå·é¿å…å†²çª
	counter := 1
	for {
		if _, err := os.Stat(failedPath); os.IsNotExist(err) {
			break // æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¯ä»¥ä½¿ç”¨è¿™ä¸ªæ–‡ä»¶å
		}
		// æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ åºå·
		failedFilename = fmt.Sprintf("%s_%d%s", cleanedName, counter, ext)
		failedPath = filepath.Join(s.failedFilesDir, failedFilename)
		counter++
	}

	// å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›ï¼ˆå¯èƒ½å·²ç»è¢«åˆ é™¤ï¼‰
	if _, err := os.Stat(filePath); os.IsNotExist(err) {
		return fmt.Errorf("æºæ–‡ä»¶ä¸å­˜åœ¨: %s", filePath)
	}

	// ç§»åŠ¨æ–‡ä»¶åˆ°å¤±è´¥ç›®å½•
	if err := os.Rename(filePath, failedPath); err != nil {
		// å¦‚æœé‡å‘½åå¤±è´¥ï¼ˆå¯èƒ½è·¨æ–‡ä»¶ç³»ç»Ÿï¼‰ï¼Œå°è¯•å¤åˆ¶ååˆ é™¤
		if err := s.copyFile(filePath, failedPath); err != nil {
			return fmt.Errorf("ç§»åŠ¨å¤±è´¥æ–‡ä»¶å¤±è´¥: %v", err)
		}
		os.Remove(filePath) // åˆ é™¤åŸæ–‡ä»¶
	}

	log.Printf("å¤±è´¥æ–‡ä»¶å·²ä¿å­˜: %s, åŸå› : %s", failedPath, reason)
	return nil
}

// copyFile å¤åˆ¶æ–‡ä»¶ï¼ˆç”¨äºè·¨æ–‡ä»¶ç³»ç»Ÿç§»åŠ¨ï¼‰
func (s *Server) copyFile(src, dst string) error {
	sourceFile, err := os.Open(src)
	if err != nil {
		return err
	}
	defer sourceFile.Close()

	destFile, err := os.Create(dst)
	if err != nil {
		return err
	}
	defer destFile.Close()

	_, err = io.Copy(destFile, sourceFile)
	return err
}

// checkAdminAuth æ£€æŸ¥ç®¡ç†å‘˜æƒé™
func (s *Server) checkAdminAuth(r *http.Request) bool {
	// ä»Headerè·å–token
	token := r.Header.Get("Authorization")
	if token != "" {
		// æ”¯æŒ "Bearer token" æ ¼å¼
		token = strings.TrimPrefix(token, "Bearer ")
		return token == s.adminToken
	}

	// ä»Queryå‚æ•°è·å–token
	token = r.URL.Query().Get("token")
	return token == s.adminToken
}

// getStackTrace è·å–å½“å‰goroutineçš„å †æ ˆè·Ÿè¸ªä¿¡æ¯
func getStackTrace() string {
	buf := make([]byte, 4096)
	n := runtime.Stack(buf, false)
	return string(buf[:n])
}

// startAsyncCheckWorkers å¯åŠ¨å¼‚æ­¥æ£€æŸ¥å·¥ä½œåç¨‹
// è¿™äº›åç¨‹ä¼šä»é˜Ÿåˆ—ä¸­å–å‡ºæ–‡æ¡£æ£€æŸ¥ä»»åŠ¡ï¼Œåœ¨åå°å¼‚æ­¥æ‰§è¡Œ
func (s *Server) startAsyncCheckWorkers() {
	for i := 0; i < s.checkWorkers; i++ {
		go func(workerID int) {
			log.Printf("å¯åŠ¨å¼‚æ­¥æ£€æŸ¥å·¥ä½œåç¨‹ #%d", workerID)
			for group := range s.checkQueue {
				func() {
					defer func() {
						if r := recover(); r != nil {
							log.Printf("âš ï¸ å¼‚æ­¥æ£€æŸ¥å·¥ä½œåç¨‹ #%d å‘ç”Ÿpanic: %v, æ–‡æ¡£: %s", workerID, r, group.DocTitle)
						}
					}()
					
					// æ‰§è¡Œæ£€æŸ¥
					log.Printf("[å·¥ä½œåç¨‹ #%d] å¼€å§‹æ£€æŸ¥æ–‡æ¡£: %s (FileID: %s)", workerID, group.DocTitle, group.FileID)
					s.checkPublicFormAsync(group)
					
					// æ›´æ–°ç¼“å­˜
					if group.FileID != "" {
						s.publicFormCache.Store(group.FileID, group.HasPublicForm)
						if group.HasPublicForm {
							log.Printf("[å·¥ä½œåç¨‹ #%d] âœ… æ–‡æ¡£ %s æ£€æŸ¥å®Œæˆï¼ŒåŒ…å«'å…¬å¼€å½¢å¼'ï¼Œå·²æ›´æ–°ç¼“å­˜", workerID, group.DocTitle)
						} else {
							log.Printf("[å·¥ä½œåç¨‹ #%d] âœ… æ–‡æ¡£ %s æ£€æŸ¥å®Œæˆï¼Œä¸åŒ…å«'å…¬å¼€å½¢å¼'ï¼Œå·²æ›´æ–°ç¼“å­˜", workerID, group.DocTitle)
						}
					}
				}()
			}
			log.Printf("å¼‚æ­¥æ£€æŸ¥å·¥ä½œåç¨‹ #%d å·²é€€å‡º", workerID)
		}(i)
	}
	log.Printf("å·²å¯åŠ¨ %d ä¸ªå¼‚æ­¥æ£€æŸ¥å·¥ä½œåç¨‹", s.checkWorkers)
}

// checkPublicFormAsync å¼‚æ­¥æ£€æŸ¥æ–‡æ¡£æ˜¯å¦åŒ…å«"å…¬å¼€å½¢å¼"ï¼ˆä¸é˜»å¡ä¸»è¯·æ±‚ï¼‰
// åªè¯»å–æ–‡æ¡£æœ€å100ä¸ªå­—ç¬¦è¿›è¡Œæ£€æŸ¥
func (s *Server) checkPublicFormAsync(group *DocGroup) {
	fileTypeLower := strings.ToLower(group.FileType)
	if fileTypeLower != "pdf" && fileTypeLower != "doc" && fileTypeLower != "docx" && fileTypeLower != "txt" {
		group.HasPublicForm = false
		return
	}

	// æ£€æŸ¥æ–‡ä»¶è·¯å¾„
	if group.FileID == "" {
		group.HasPublicForm = false
		return
	}

	fileInfo, exists := s.files[group.FileID]
	if !exists {
		group.HasPublicForm = false
		return
	}

	// æ„å»ºæ–‡ä»¶è·¯å¾„
	var filePath string
	newFormatPath := filepath.Join(s.filesDir, group.FileID+"_"+fileInfo.Filename)
	oldFormatPath := filepath.Join(s.filesDir, group.FileID+filepath.Ext(fileInfo.Filename))

	if _, err := os.Stat(newFormatPath); err == nil {
		filePath = newFormatPath
	} else if _, err := os.Stat(oldFormatPath); err == nil {
		filePath = oldFormatPath
	} else {
		group.HasPublicForm = false
		return
	}

	// åªè¯»å–æœ€å100ä¸ªå­—ç¬¦è¿›è¡Œæ£€æŸ¥
	const maxCheckLength = 100
	var contentToCheck string

	if fileTypeLower == "txt" {
		if fileContent, err := readFileLastBytes(filePath, maxCheckLength); err == nil {
			contentToCheck = fileContent
			log.Printf("[å¼‚æ­¥æ£€æŸ¥] TXTæ–‡ä»¶ %s è¯»å–çš„æœ€å100ä¸ªå­—ç¬¦: [%s]", group.DocTitle, contentToCheck)
		} else {
			log.Printf("[å¼‚æ­¥æ£€æŸ¥] TXTæ–‡ä»¶ %s è¯»å–å¤±è´¥: %v", group.DocTitle, err)
		}
	} else if fileTypeLower == "pdf" || fileTypeLower == "doc" || fileTypeLower == "docx" {
		lastContent, err := loadDocumentLastPart(filePath, fileTypeLower, maxCheckLength)
		if err == nil && lastContent != "" {
			if len(lastContent) > maxCheckLength {
				contentToCheck = lastContent[len(lastContent)-maxCheckLength:]
			} else {
				contentToCheck = lastContent
			}
			log.Printf("[å¼‚æ­¥æ£€æŸ¥] %sæ–‡ä»¶ %s è¯»å–çš„æœ€å100ä¸ªå­—ç¬¦: [%s]", strings.ToUpper(fileTypeLower), group.DocTitle, contentToCheck)
			log.Printf("[å¼‚æ­¥æ£€æŸ¥] åŸå§‹å†…å®¹é•¿åº¦: %d, æˆªå–åé•¿åº¦: %d", len(lastContent), len(contentToCheck))
		} else {
			log.Printf("[å¼‚æ­¥æ£€æŸ¥] %sæ–‡ä»¶ %s è¯»å–å¤±è´¥: %v", strings.ToUpper(fileTypeLower), group.DocTitle, err)
		}
	}

	// æ‰“å°è¯»å–åˆ°çš„å†…å®¹ç”¨äºè°ƒè¯•
	if contentToCheck != "" {
		log.Printf("[å¼‚æ­¥æ£€æŸ¥] æ–‡æ¡£ %s (FileID: %s) è¯»å–åˆ°çš„æœ€å100ä¸ªå­—ç¬¦å†…å®¹: [%s]", group.DocTitle, group.FileID, contentToCheck)
		log.Printf("[å¼‚æ­¥æ£€æŸ¥] å†…å®¹é•¿åº¦: %d å­—ç¬¦", len(contentToCheck))
		// æ£€æŸ¥æ˜¯å¦åŒ…å«"å…¬å¼€å½¢å¼"å­—ç¬¦ä¸²
		if strings.Contains(contentToCheck, "å…¬å¼€å½¢å¼") {
			log.Printf("[å¼‚æ­¥æ£€æŸ¥] âœ… åœ¨å†…å®¹ä¸­æ‰¾åˆ°äº†'å…¬å¼€å½¢å¼'å­—ç¬¦ä¸²")
		} else {
			log.Printf("[å¼‚æ­¥æ£€æŸ¥] âŒ åœ¨å†…å®¹ä¸­æœªæ‰¾åˆ°'å…¬å¼€å½¢å¼'å­—ç¬¦ä¸²")
		}
	} else {
		log.Printf("[å¼‚æ­¥æ£€æŸ¥] âš ï¸ æ–‡æ¡£ %s è¯»å–åˆ°çš„å†…å®¹ä¸ºç©º", group.DocTitle)
	}

	// æ£€æŸ¥æ˜¯å¦åŒ…å«"å…¬å¼€å½¢å¼"
	hasPublicForm := checkPublicFormInContent(contentToCheck)
	log.Printf("[å¼‚æ­¥æ£€æŸ¥] checkPublicFormInContent è¿”å›ç»“æœ: %v", hasPublicForm)
	group.HasPublicForm = hasPublicForm
}
